<!DOCTYPE HTML>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="flink实时数仓, HTML,CSS,JavaScript,JQuery,java,linux">
    <meta name="description" content="本网址是个人兴趣爱好，总结分享经验，记录生活点滴的平台，希望在以后的嘘唏旅途中，走出自己的风景。">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>flink实时数仓 | 情深骚明&amp;博客</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>
    <script src="http://echarts.baidu.com/dist/echarts.common.min.js"></script>

<meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>




<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">情深骚明&amp;博客</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>Contact</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">情深骚明&amp;博客</div>
        <div class="logo-desc">
            
            本网址是个人兴趣爱好，总结分享经验，记录生活点滴的平台，希望在以后的嘘唏旅途中，走出自己的风景。
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			About
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			Contact
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/5.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">flink实时数仓</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/flink/">
                                <span class="chip bg-color">flink</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/flink/" class="post-category">
                                flink
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2021-07-13
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="flink实时数仓"><a href="#flink实时数仓" class="headerlink" title="flink实时数仓"></a>flink实时数仓</h1><h2 id="面试题"><a href="#面试题" class="headerlink" title="面试题"></a>面试题</h2><h3 id="HBASE面试题"><a href="#HBASE面试题" class="headerlink" title="HBASE面试题"></a>HBASE面试题</h3><ul>
<li>读、写、更新</li>
</ul>
<h4 id="1、HBASE详细架构图"><a href="#1、HBASE详细架构图" class="headerlink" title="1、HBASE详细架构图"></a>1、HBASE详细架构图</h4><p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210715112038448.png" alt="HBASE详细架构图"></p>
<h4 id="2、HBASE写数据流程"><a href="#2、HBASE写数据流程" class="headerlink" title="2、HBASE写数据流程"></a>2、HBASE写数据流程</h4><p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210715112234032.png" alt="HBASE写数据流程"></p>
<h4 id="3、HBASE读数据流程"><a href="#3、HBASE读数据流程" class="headerlink" title="3、HBASE读数据流程"></a>3、HBASE读数据流程</h4><p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210715112343002.png" alt="HBASE读数据流程"></p>
<h4 id="4、HBASE-FLush流程"><a href="#4、HBASE-FLush流程" class="headerlink" title="4、HBASE FLush流程"></a>4、HBASE FLush流程</h4><h4 id="5、合并-amp-切分流程"><a href="#5、合并-amp-切分流程" class="headerlink" title="5、合并 &amp; 切分流程"></a>5、合并 &amp; 切分流程</h4><h4 id="6、RowKey设计"><a href="#6、RowKey设计" class="headerlink" title="6、RowKey设计"></a>6、RowKey设计</h4><h2 id="实时数仓"><a href="#实时数仓" class="headerlink" title="实时数仓"></a>实时数仓</h2><h3 id="1、动态分流"><a href="#1、动态分流" class="headerlink" title="1、动态分流"></a>1、动态分流</h3><h3 id="2、旁路缓存"><a href="#2、旁路缓存" class="headerlink" title="2、旁路缓存"></a>2、旁路缓存</h3><h3 id="3、异步查询"><a href="#3、异步查询" class="headerlink" title="3、异步查询"></a>3、异步查询</h3><h2 id="HBASE-和-Phoenix结合"><a href="#HBASE-和-Phoenix结合" class="headerlink" title="HBASE 和 Phoenix结合"></a>HBASE 和 Phoenix结合</h2><ul>
<li>版本选择：phoenix-5.0.0-HBASE-2.0-bin</li>
<li>这个可以去查看hbase高版本的博客，这个是已经部署好了</li>
</ul>
<h2 id="DWD层-行为数据"><a href="#DWD层-行为数据" class="headerlink" title="DWD层-行为数据"></a>DWD层-行为数据</h2><ul>
<li>识别新老用户 —&gt; 状态校验、RichProcessFunction富合函数</li>
<li>侧输出流做数据拆分</li>
<li>将数据输出到Kafka Topic中（页面日志 —&gt; 主流 | 启动日志、曝光日志 —&gt; 侧输出流）</li>
<li>业务数据：都是状态编程，行为数据要简单得很多</li>
</ul>
<h3 id="1、接收Kafka的数据，并进行转换"><a href="#1、接收Kafka的数据，并进行转换" class="headerlink" title="1、接收Kafka的数据，并进行转换"></a>1、接收Kafka的数据，并进行转换</h3><h4 id="1-1-封装操作Kafka的工具类，并提供获取Kafka消费者的方法"><a href="#1-1-封装操作Kafka的工具类，并提供获取Kafka消费者的方法" class="headerlink" title="1.1 封装操作Kafka的工具类，并提供获取Kafka消费者的方法"></a>1.1 封装操作Kafka的工具类，并提供获取Kafka消费者的方法</h4><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wmy.flink.warehourse.utils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.serialization.SimpleStringSchema;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName:MyKafkaUtil</span></span><br><span class="line"><span class="comment"> * Package:com.wmy.flink.warehourse.utils</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span>:2021/7/13 16:46</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>:数仓开发工程师</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@email</span>:2647716549@qq.com</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>: kafka消费者的工具类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyKafkaUtil</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> String KAFKA_SERVER = <span class="string">"yaxin01:9092,yaxin02:9092,yaxin03:9092"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取Kafka Source的方法</span></span><br><span class="line"><span class="comment">     * FlinkKafkaConsumer ---&gt; FlinkKafkaConsumerBase ---&gt; RichParallelSourceFunction</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> topic</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> groupID</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> FlinkKafkaConsumer&lt;String&gt; <span class="title">getKafkaSource</span><span class="params">(String topic,String groupID)</span> </span>{</span><br><span class="line">        <span class="comment">// 1、创建Kafka的配置信息</span></span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2、配置kafka消费参数</span></span><br><span class="line">        props.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, KAFKA_SERVER);</span><br><span class="line">        props.setProperty(ConsumerConfig.GROUP_ID_CONFIG, groupID);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3、获取kafkaSource</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> FlinkKafkaConsumer&lt;String&gt;(topic, <span class="keyword">new</span> SimpleStringSchema(), props);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>

<h4 id="1-2-读取kafka的数据进行新老用户的处理"><a href="#1-2-读取kafka的数据进行新老用户的处理" class="headerlink" title="1.2 读取kafka的数据进行新老用户的处理"></a>1.2 读取kafka的数据进行新老用户的处理</h4><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wmy.flink.warehourse.app.dwd;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSON;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONObject;</span><br><span class="line"><span class="keyword">import</span> com.wmy.flink.warehourse.utils.MyKafkaUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.RichMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.ValueState;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.ValueStateDescriptor;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.runtime.state.filesystem.FsStateBackend;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.CheckpointingMode;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.KeyedStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName:LogBaseApp</span></span><br><span class="line"><span class="comment"> * Package:com.wmy.flink.warehourse.app.dwd</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span>:2021/7/13 16:22</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>:数仓开发工程师</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@email</span>:2647716549@qq.com</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>: 接收Kafka的数据，并进行转换</span></span><br><span class="line"><span class="comment"> * 1) 封装操作Kafka的工具类，并提供获取Kafka消费者的方法</span></span><br><span class="line"><span class="comment"> * 测试Kafka数据读取问题</span></span><br><span class="line"><span class="comment"> *  a）启动集群：Zookeeper\Kafka\HDFS</span></span><br><span class="line"><span class="comment"> *  b）启动Kafka生产者：kafka-console-producer.sh --broker-list yaxin01:9092 --topic ods_base_log</span></span><br><span class="line"><span class="comment"> *  c）测试数据：{"common":{"ar":"110000","uid":"7","os":"Android 11.0","ch":"xiaomi","is_new":"1","md":"Xiaomi 9","mid":"mid_41","vc":"v2.1.132","vc":"v2.1.134","ba":"Xiaomi"},"start":{"entry":"icon","loading_time":7815,"open_ad_id":8,"open_ad_ms":7872,"open_ad_skip_ms":6115},"ts":1592175234000}</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LogBaseApp</span> </span>{</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>{</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 注意：会出现一个没有权限的错误</span></span><br><span class="line">        System.setProperty(<span class="string">"HADOOP_USER_NAME"</span>, <span class="string">"root"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1、获取执行环境，设置并行度，设置状态后端（HDFS）、checkpoint，local模式是不能设置状态恢复的</span></span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>); <span class="comment">// kafka topic partitions nums</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1.1 设置状态后端</span></span><br><span class="line">        env.setStateBackend(<span class="keyword">new</span> FsStateBackend(<span class="string">"hdfs://yaxin01:9820/flink-realtime-warehourse/dwd"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1.2 开启CheckPoint的</span></span><br><span class="line">        env.enableCheckpointing(<span class="number">10000L</span>, CheckpointingMode.EXACTLY_ONCE); <span class="comment">// 每隔多少时间开启checkpoint</span></span><br><span class="line">        env.getCheckpointConfig().setCheckpointTimeout(<span class="number">60000L</span>); <span class="comment">// 超时时间为一分钟</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2、读取kafka_ods_base_log 主题数据</span></span><br><span class="line">        <span class="comment">// 2.1 封装一个消费Kafka的工具类</span></span><br><span class="line">        FlinkKafkaConsumer&lt;String&gt; kafkaSource = MyKafkaUtil.getKafkaSource(<span class="string">"ods_base_log"</span>, <span class="string">"dwd_log"</span>);</span><br><span class="line">        DataStreamSource&lt;String&gt; kafkaDS = env.addSource(kafkaSource);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3、将每行数据转换为JsonObject</span></span><br><span class="line">        SingleOutputStreamOperator&lt;JSONObject&gt; jsonObjectDS = kafkaDS.map(JSON::parseObject);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4、按照ID分组</span></span><br><span class="line">        KeyedStream&lt;JSONObject, String&gt; keyedStream = jsonObjectDS.keyBy(data -&gt; data.getJSONObject(<span class="string">"common"</span>).getString(<span class="string">"mid"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5、使用状态做新老用户校验 ---&gt; 使用复合函数</span></span><br><span class="line">        SingleOutputStreamOperator&lt;JSONObject&gt; jsonWithNewFlagDS = keyedStream.map(<span class="keyword">new</span> NewMidRichMapFunc());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 打印测试</span></span><br><span class="line">        jsonWithNewFlagDS.print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6、分流，使用ProcessFunction将ODS数据拆分成启动、曝光以及页面数据</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 7、将三个流的数据写入到对应的Kafka主题</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 8、执行任务</span></span><br><span class="line">        env.execute(<span class="string">"read kafka source write kafka topic ... "</span>);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 做一个字段的校验</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">NewMidRichMapFunc</span> <span class="keyword">extends</span> <span class="title">RichMapFunction</span>&lt;<span class="title">JSONObject</span>,<span class="title">JSONObject</span>&gt; </span>{</span><br><span class="line">        <span class="comment">// 声明状态，用于表示当前mid是否以及访问过</span></span><br><span class="line">        <span class="keyword">private</span> ValueState&lt;String&gt; firstVisitDateState;</span><br><span class="line">        <span class="keyword">private</span> SimpleDateFormat simpleDateFormat;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>{</span><br><span class="line">            firstVisitDateState = getRuntimeContext().getState(<span class="keyword">new</span> ValueStateDescriptor&lt;String&gt;(<span class="string">"new-mid"</span>, String.class));</span><br><span class="line">            simpleDateFormat = <span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyy-MM-dd"</span>);</span><br><span class="line">        }</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> JSONObject <span class="title">map</span><span class="params">(JSONObject value)</span> <span class="keyword">throws</span> Exception </span>{</span><br><span class="line">            <span class="comment">// 取出新用户标记</span></span><br><span class="line">            String isNew = value.getJSONObject(<span class="string">"common"</span>).getString(<span class="string">"is_new"</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 如果当前前端传输数据表示为新用户，则进行校验</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="string">"1"</span>.equals(isNew)) {</span><br><span class="line">                <span class="comment">// 取出状态数据，并取出当前访问时间</span></span><br><span class="line">                String firstDate = firstVisitDateState.value();</span><br><span class="line">                Long ts = value.getLong(<span class="string">"ts"</span>);</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 判断状态数据是否为null</span></span><br><span class="line">                <span class="keyword">if</span> (firstDate != <span class="keyword">null</span>) {</span><br><span class="line">                    <span class="comment">// 修复</span></span><br><span class="line">                    value.getJSONObject(<span class="string">"common"</span>).put(<span class="string">"is_new"</span>, <span class="number">0</span>);</span><br><span class="line">                } <span class="keyword">else</span> {</span><br><span class="line">                    <span class="comment">// 更新数据</span></span><br><span class="line">                    firstVisitDateState.update(simpleDateFormat.format(ts));</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">            <span class="keyword">return</span> value;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>

<h4 id="1-3-测试数据"><a href="#1-3-测试数据" class="headerlink" title="1.3 测试数据"></a>1.3 测试数据</h4><figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">{<span class="attr">"common"</span>:{<span class="attr">"ar"</span>:<span class="string">"110000"</span>,<span class="attr">"uid"</span>:<span class="string">"7"</span>,<span class="attr">"os"</span>:<span class="string">"Android 11.0"</span>,<span class="attr">"ch"</span>:<span class="string">"xiaomi"</span>,<span class="attr">"is_new"</span>:<span class="string">"1"</span>,<span class="attr">"md"</span>:<span class="string">"Xiaomi 9"</span>,<span class="attr">"mid"</span>:<span class="string">"mid_41"</span>,<span class="attr">"vc"</span>:<span class="string">"v2.1.132"</span>,<span class="attr">"vc"</span>:<span class="string">"v2.1.134"</span>,<span class="attr">"ba"</span>:<span class="string">"Xiaomi"</span>},<span class="attr">"start"</span>:{<span class="attr">"entry"</span>:<span class="string">"icon"</span>,<span class="attr">"loading_time"</span>:<span class="number">7815</span>,<span class="attr">"open_ad_id"</span>:<span class="number">8</span>,<span class="attr">"open_ad_ms"</span>:<span class="number">7872</span>,<span class="attr">"open_ad_skip_ms"</span>:<span class="number">6115</span>},<span class="attr">"ts"</span>:<span class="number">1592175234000</span>}</span><br></pre></td></tr></tbody></table></figure>

<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210713173720628.png" alt="kafka生产数据"></p>
<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210713173745167.png" alt="idea运行结果"></p>
<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210713173847564.png" alt="Flink任务设置 状态后端的数据"></p>
<h4 id="1-4-读取Kafka数据经过新老用户处理之后进行分流操作"><a href="#1-4-读取Kafka数据经过新老用户处理之后进行分流操作" class="headerlink" title="1.4 读取Kafka数据经过新老用户处理之后进行分流操作"></a>1.4 读取Kafka数据经过新老用户处理之后进行分流操作</h4><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wmy.flink.warehourse.app.dwd;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSON;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONArray;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONObject;</span><br><span class="line"><span class="keyword">import</span> com.wmy.flink.warehourse.utils.MyKafkaUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.RichMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.ValueState;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.ValueStateDescriptor;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.runtime.state.filesystem.FsStateBackend;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.CheckpointingMode;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.KeyedStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.ProcessFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.OutputTag;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName:LogBaseApp</span></span><br><span class="line"><span class="comment"> * Package:com.wmy.flink.warehourse.app.dwd</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span>:2021/7/13 16:22</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>:数仓开发工程师</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@email</span>:2647716549@qq.com</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>: 接收Kafka的数据，并进行转换</span></span><br><span class="line"><span class="comment"> * 1) 封装操作Kafka的工具类，并提供获取Kafka消费者的方法</span></span><br><span class="line"><span class="comment"> * 测试Kafka数据读取问题</span></span><br><span class="line"><span class="comment"> *  a）启动集群：Zookeeper\Kafka\HDFS</span></span><br><span class="line"><span class="comment"> *  b）启动Kafka生产者：kafka-console-producer.sh --broker-list yaxin01:9092 --topic ods_base_log</span></span><br><span class="line"><span class="comment"> *  c）测试数据：{"common":{"ar":"110000","uid":"7","os":"Android 11.0","ch":"xiaomi","is_new":"1","md":"Xiaomi 9","mid":"mid_41","vc":"v2.1.132","vc":"v2.1.134","ba":"Xiaomi"},"start":{"entry":"icon","loading_time":7815,"open_ad_id":8,"open_ad_ms":7872,"open_ad_skip_ms":6115},"ts":1592175234000}</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LogBaseApp</span> </span>{</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>{</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 注意：会出现一个没有权限的错误</span></span><br><span class="line">        System.setProperty(<span class="string">"HADOOP_USER_NAME"</span>, <span class="string">"root"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1、获取执行环境，设置并行度，设置状态后端（HDFS）、checkpoint，local模式是不能设置状态恢复的</span></span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>); <span class="comment">// kafka topic partitions nums</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1.1 设置状态后端</span></span><br><span class="line">        <span class="comment">//env.setStateBackend(new FsStateBackend("hdfs://yaxin01:9820/flink-realtime-warehourse/dwd"));</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1.2 开启CheckPoint的</span></span><br><span class="line">        <span class="comment">//env.enableCheckpointing(10000L, CheckpointingMode.EXACTLY_ONCE); // 每隔多少时间开启checkpoint</span></span><br><span class="line">        <span class="comment">//env.getCheckpointConfig().setCheckpointTimeout(60000L); // 超时时间为一分钟</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2、读取kafka_ods_base_log 主题数据</span></span><br><span class="line">        <span class="comment">// 2.1 封装一个消费Kafka的工具类</span></span><br><span class="line">        FlinkKafkaConsumer&lt;String&gt; kafkaSource = MyKafkaUtil.getKafkaSource(<span class="string">"ods_base_log"</span>, <span class="string">"dwd_log"</span>);</span><br><span class="line">        DataStreamSource&lt;String&gt; kafkaDS = env.addSource(kafkaSource);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3、将每行数据转换为JsonObject</span></span><br><span class="line">        SingleOutputStreamOperator&lt;JSONObject&gt; jsonObjectDS = kafkaDS.map(JSON::parseObject);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4、按照ID分组</span></span><br><span class="line">        KeyedStream&lt;JSONObject, String&gt; keyedStream = jsonObjectDS.keyBy(data -&gt; data.getJSONObject(<span class="string">"common"</span>).getString(<span class="string">"mid"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5、使用状态做新老用户校验 ---&gt; 使用复合函数</span></span><br><span class="line">        SingleOutputStreamOperator&lt;JSONObject&gt; jsonWithNewFlagDS = keyedStream.map(<span class="keyword">new</span> NewMidRichMapFunc());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 打印测试</span></span><br><span class="line">        <span class="comment">//jsonWithNewFlagDS.print();</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6、分流，使用ProcessFunction将ODS数据拆分成启动、曝光以及页面数据</span></span><br><span class="line">        SingleOutputStreamOperator&lt;String&gt; pageDS = jsonWithNewFlagDS.process(<span class="keyword">new</span> SpiltProcessFunc());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 7、将三个流的数据写入到对应的Kafka主题</span></span><br><span class="line">        DataStream&lt;String&gt; startDS = pageDS.getSideOutput(<span class="keyword">new</span> OutputTag&lt;String&gt;(<span class="string">"start"</span>) {</span><br><span class="line">        });</span><br><span class="line">        DataStream&lt;String&gt; displayDS = pageDS.getSideOutput(<span class="keyword">new</span> OutputTag&lt;String&gt;(<span class="string">"display"</span>) {</span><br><span class="line">        });</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 打印测试</span></span><br><span class="line">        pageDS.print(<span class="string">"page &gt;&gt;&gt;&gt;&gt;&gt;&gt; "</span>);</span><br><span class="line">        startDS.print(<span class="string">"start &gt;&gt;&gt;&gt;&gt;&gt;&gt; "</span>);</span><br><span class="line">        displayDS.print(<span class="string">"display &gt;&gt;&gt;&gt;&gt;&gt;&gt; "</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 8、执行任务</span></span><br><span class="line">        env.execute(<span class="string">"read kafka source write kafka topic ... "</span>);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 做一个字段的校验</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">NewMidRichMapFunc</span> <span class="keyword">extends</span> <span class="title">RichMapFunction</span>&lt;<span class="title">JSONObject</span>,<span class="title">JSONObject</span>&gt; </span>{</span><br><span class="line">        <span class="comment">// 声明状态，用于表示当前mid是否以及访问过</span></span><br><span class="line">        <span class="keyword">private</span> ValueState&lt;String&gt; firstVisitDateState;</span><br><span class="line">        <span class="keyword">private</span> SimpleDateFormat simpleDateFormat;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>{</span><br><span class="line">            firstVisitDateState = getRuntimeContext().getState(<span class="keyword">new</span> ValueStateDescriptor&lt;String&gt;(<span class="string">"new-mid"</span>, String.class));</span><br><span class="line">            simpleDateFormat = <span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyy-MM-dd"</span>);</span><br><span class="line">        }</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> JSONObject <span class="title">map</span><span class="params">(JSONObject value)</span> <span class="keyword">throws</span> Exception </span>{</span><br><span class="line">            <span class="comment">// 取出新用户标记</span></span><br><span class="line">            String isNew = value.getJSONObject(<span class="string">"common"</span>).getString(<span class="string">"is_new"</span>);</span><br><span class="line">            <span class="comment">// 如果当前前端传输数据表示为新用户，则进行校验</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="string">"1"</span>.equals(isNew)) {</span><br><span class="line">                <span class="comment">// 取出状态数据，并取出当前访问时间</span></span><br><span class="line">                String firstDate = firstVisitDateState.value();</span><br><span class="line">                Long ts = value.getLong(<span class="string">"ts"</span>);</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 判断状态数据是否为null</span></span><br><span class="line">                <span class="keyword">if</span> (firstDate != <span class="keyword">null</span>) {</span><br><span class="line">                    <span class="comment">// 修复</span></span><br><span class="line">                    value.getJSONObject(<span class="string">"common"</span>).put(<span class="string">"is_new"</span>, <span class="number">0</span>);</span><br><span class="line">                } <span class="keyword">else</span> {</span><br><span class="line">                    <span class="comment">// 更新数据</span></span><br><span class="line">                    firstVisitDateState.update(simpleDateFormat.format(ts));</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">            <span class="keyword">return</span> value;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将数据分流到kafka中</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SpiltProcessFunc</span> <span class="keyword">extends</span> <span class="title">ProcessFunction</span>&lt;<span class="title">JSONObject</span>,<span class="title">String</span>&gt;</span>{</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(JSONObject value, Context ctx, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception </span>{</span><br><span class="line">            <span class="comment">// 提前"start字段"</span></span><br><span class="line">            String startStr = value.getString(<span class="string">"start"</span>);</span><br><span class="line">            <span class="comment">// 判断是否为启动数据</span></span><br><span class="line">            <span class="keyword">if</span> (startStr != <span class="keyword">null</span> &amp;&amp; startStr.length() &gt; <span class="number">0</span>) {</span><br><span class="line">                <span class="comment">// 将启动日志输出到侧输出流</span></span><br><span class="line">                ctx.output(<span class="keyword">new</span> OutputTag&lt;String&gt;(<span class="string">"start"</span>){}, value.toString());</span><br><span class="line">            } <span class="keyword">else</span> {</span><br><span class="line">                <span class="comment">// 不是启动日志，继续判断是否是曝光数据</span></span><br><span class="line">                JSONArray displays = value.getJSONArray(<span class="string">"displays"</span>);</span><br><span class="line">                <span class="keyword">if</span> (displays != <span class="keyword">null</span> &amp;&amp; displays.size() &gt; <span class="number">0</span>) {</span><br><span class="line">                    <span class="comment">// 曝光数据，是一个数组类型的，遍历写入侧输出流</span></span><br><span class="line">                    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; displays.size(); i++) {</span><br><span class="line">                        <span class="comment">// 取出单条曝光数据</span></span><br><span class="line">                        JSONObject displayJson = displays.getJSONObject(i);</span><br><span class="line">                        <span class="comment">// 添加页面ID</span></span><br><span class="line">                        displayJson.put(<span class="string">"page_id"</span>, value.getJSONObject(<span class="string">"page"</span>).getString(<span class="string">"page_id"</span>));</span><br><span class="line">                        <span class="comment">// 输出到侧输出流中</span></span><br><span class="line">                        ctx.output(<span class="keyword">new</span> OutputTag&lt;String&gt;(<span class="string">"display"</span>){}, displayJson.toString());</span><br><span class="line">                    }</span><br><span class="line">                } <span class="keyword">else</span> {</span><br><span class="line">                    <span class="comment">// 页面数据，将数据输出到主流，主流使用collect</span></span><br><span class="line">                    out.collect(value.toString());</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>

<h4 id="1-5-测试数据"><a href="#1-5-测试数据" class="headerlink" title="1.5 测试数据"></a>1.5 测试数据</h4><figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- 启动日志</span><br><span class="line">{<span class="attr">"common"</span>:{<span class="attr">"ar"</span>:<span class="string">"310000"</span>,<span class="attr">"ba"</span>:<span class="string">"Xiaomi"</span>,<span class="attr">"ch"</span>:<span class="string">"xiaomi"</span>,<span class="attr">"md"</span>:<span class="string">"Xiaomi 10 Pro "</span>,<span class="attr">"mid"</span>:<span class="string">"mid_7"</span>,<span class="attr">"os"</span>:<span class="string">"Android 10.0"</span>,<span class="attr">"uid"</span>:<span class="string">"177"</span>,<span class="attr">"vc"</span>:<span class="string">"v2.1.134"</span>},<span class="attr">"start"</span>:{<span class="attr">"entry"</span>:<span class="string">"icon"</span>,<span class="attr">"loading_time"</span>:<span class="number">15351</span>,<span class="attr">"open_ad_id"</span>:<span class="number">19</span>,<span class="attr">"open_ad_ms"</span>:<span class="number">8660</span>,<span class="attr">"open_ad_skip_ms"</span>:<span class="number">0</span>},<span class="attr">"ts"</span>:<span class="number">1592179997000</span>}</span><br><span class="line"></span><br><span class="line">-- 曝光数据</span><br><span class="line">{<span class="attr">"common"</span>:{<span class="attr">"ar"</span>:<span class="string">"310000"</span>,<span class="attr">"ba"</span>:<span class="string">"Xiaomi"</span>,<span class="attr">"ch"</span>:<span class="string">"xiaomi"</span>,<span class="attr">"md"</span>:<span class="string">"Xiaomi 10 Pro "</span>,<span class="attr">"mid"</span>:<span class="string">"mid_7"</span>,<span class="attr">"os"</span>:<span class="string">"Android 10.0"</span>,<span class="attr">"uid"</span>:<span class="string">"177"</span>,<span class="attr">"vc"</span>:<span class="string">"v2.1.134"</span>},<span class="attr">"displays"</span>:[{<span class="attr">"display_type"</span>:<span class="string">"activity"</span>,<span class="attr">"item"</span>:<span class="string">"2"</span>,<span class="attr">"item_type"</span>:<span class="string">"activity_id"</span>,<span class="attr">"order"</span>:<span class="number">1</span>},{<span class="attr">"display_type"</span>:<span class="string">"promotion"</span>,<span class="attr">"item"</span>:<span class="string">"9"</span>,<span class="attr">"item_type"</span>:<span class="string">"sku_id"</span>,<span class="attr">"order"</span>:<span class="number">2</span>},{<span class="attr">"display_type"</span>:<span class="string">"promotion"</span>,<span class="attr">"item"</span>:<span class="string">"7"</span>,<span class="attr">"item_type"</span>:<span class="string">"sku_id"</span>,<span class="attr">"order"</span>:<span class="number">3</span>},{<span class="attr">"display_type"</span>:<span class="string">"promotion"</span>,<span class="attr">"item"</span>:<span class="string">"9"</span>,<span class="attr">"item_type"</span>:<span class="string">"sku_id"</span>,<span class="attr">"order"</span>:<span class="number">4</span>},{<span class="attr">"display_type"</span>:<span class="string">"recommend"</span>,<span class="attr">"item"</span>:<span class="string">"1"</span>,<span class="attr">"item_type"</span>:<span class="string">"sku_id"</span>,<span class="attr">"order"</span>:<span class="number">5</span>},{<span class="attr">"display_type"</span>:<span class="string">"query"</span>,<span class="attr">"item"</span>:<span class="string">"8"</span>,<span class="attr">"item_type"</span>:<span class="string">"sku_id"</span>,<span class="attr">"order"</span>:<span class="number">6</span>}],<span class="attr">"page"</span>:{<span class="attr">"during_time"</span>:<span class="number">18532</span>,<span class="attr">"page_id"</span>:<span class="string">"home"</span>},<span class="attr">"ts"</span>:<span class="number">1592180012351</span>}</span><br><span class="line"></span><br><span class="line">-- 页面数据</span><br><span class="line">{<span class="attr">"common"</span>:{<span class="attr">"ar"</span>:<span class="string">"310000"</span>,<span class="attr">"ba"</span>:<span class="string">"Xiaomi"</span>,<span class="attr">"ch"</span>:<span class="string">"xiaomi"</span>,<span class="attr">"md"</span>:<span class="string">"Xiaomi 10 Pro "</span>,<span class="attr">"mid"</span>:<span class="string">"mid_7"</span>,<span class="attr">"os"</span>:<span class="string">"Android 10.0"</span>,<span class="attr">"uid"</span>:<span class="string">"177"</span>,<span class="attr">"vc"</span>:<span class="string">"v2.1.134"</span>},<span class="attr">"page"</span>:{<span class="attr">"during_time"</span>:<span class="number">19041</span>,<span class="attr">"item"</span>:<span class="string">"联想"</span>,<span class="attr">"item_type"</span>:<span class="string">"keyword"</span>,<span class="attr">"last_page_id"</span>:<span class="string">"home"</span>,<span class="attr">"page_id"</span>:<span class="string">"good_list"</span>},<span class="attr">"ts"</span>:<span class="number">1592180030883</span>}</span><br></pre></td></tr></tbody></table></figure>

<h4 id="1-6-运行程序"><a href="#1-6-运行程序" class="headerlink" title="1.6 运行程序"></a>1.6 运行程序</h4><p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210713180831911.png" alt="数据输入"></p>
<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210713180854396.png" alt="Idea结果展示"></p>
<h4 id="1-7-将行为数据分流写入kafka"><a href="#1-7-将行为数据分流写入kafka" class="headerlink" title="1.7 将行为数据分流写入kafka"></a>1.7 将行为数据分流写入kafka</h4><h5 id="1-7-1-LogBaseApp"><a href="#1-7-1-LogBaseApp" class="headerlink" title="1.7.1 LogBaseApp"></a>1.7.1 LogBaseApp</h5><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wmy.flink.warehourse.app.dwd;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSON;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONArray;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONObject;</span><br><span class="line"><span class="keyword">import</span> com.wmy.flink.warehourse.utils.MyKafkaUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.RichMapFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.ValueState;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.state.ValueStateDescriptor;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.runtime.state.filesystem.FsStateBackend;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.CheckpointingMode;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.KeyedStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.ProcessFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.OutputTag;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName:LogBaseApp</span></span><br><span class="line"><span class="comment"> * Package:com.wmy.flink.warehourse.app.dwd</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span>:2021/7/13 16:22</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>:数仓开发工程师</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@email</span>:2647716549@qq.com</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>: 接收Kafka的数据，并进行转换</span></span><br><span class="line"><span class="comment"> * 1) 封装操作Kafka的工具类，并提供获取Kafka消费者的方法</span></span><br><span class="line"><span class="comment"> * 测试Kafka数据读取问题</span></span><br><span class="line"><span class="comment"> *  a）启动集群：Zookeeper\Kafka\HDFS</span></span><br><span class="line"><span class="comment"> *  b）启动Kafka生产者：kafka-console-producer.sh --broker-list yaxin01:9092 --topic ods_base_log</span></span><br><span class="line"><span class="comment"> *  c）测试数据：{"common":{"ar":"110000","uid":"7","os":"Android 11.0","ch":"xiaomi","is_new":"1","md":"Xiaomi 9","mid":"mid_41","vc":"v2.1.132","vc":"v2.1.134","ba":"Xiaomi"},"start":{"entry":"icon","loading_time":7815,"open_ad_id":8,"open_ad_ms":7872,"open_ad_skip_ms":6115},"ts":1592175234000}</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LogBaseApp</span> </span>{</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>{</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 注意：会出现一个没有权限的错误</span></span><br><span class="line">        System.setProperty(<span class="string">"HADOOP_USER_NAME"</span>, <span class="string">"root"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1、获取执行环境，设置并行度，设置状态后端（HDFS）、checkpoint，local模式是不能设置状态恢复的</span></span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>); <span class="comment">// kafka topic partitions nums</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1.1 设置状态后端</span></span><br><span class="line">        <span class="comment">//env.setStateBackend(new FsStateBackend("hdfs://yaxin01:9820/flink-realtime-warehourse/dwd"));</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1.2 开启CheckPoint的</span></span><br><span class="line">        <span class="comment">//env.enableCheckpointing(10000L, CheckpointingMode.EXACTLY_ONCE); // 每隔多少时间开启checkpoint</span></span><br><span class="line">        <span class="comment">//env.getCheckpointConfig().setCheckpointTimeout(60000L); // 超时时间为一分钟</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2、读取kafka_ods_base_log 主题数据</span></span><br><span class="line">        <span class="comment">// 2.1 封装一个消费Kafka的工具类</span></span><br><span class="line">        FlinkKafkaConsumer&lt;String&gt; kafkaSource = MyKafkaUtil.getKafkaSource(<span class="string">"ods_base_log"</span>, <span class="string">"dwd_log"</span>);</span><br><span class="line">        DataStreamSource&lt;String&gt; kafkaDS = env.addSource(kafkaSource);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3、将每行数据转换为JsonObject</span></span><br><span class="line">        SingleOutputStreamOperator&lt;JSONObject&gt; jsonObjectDS = kafkaDS.map(JSON::parseObject);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4、按照ID分组</span></span><br><span class="line">        KeyedStream&lt;JSONObject, String&gt; keyedStream = jsonObjectDS.keyBy(data -&gt; data.getJSONObject(<span class="string">"common"</span>).getString(<span class="string">"mid"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5、使用状态做新老用户校验 ---&gt; 使用复合函数</span></span><br><span class="line">        SingleOutputStreamOperator&lt;JSONObject&gt; jsonWithNewFlagDS = keyedStream.map(<span class="keyword">new</span> NewMidRichMapFunc());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 打印测试</span></span><br><span class="line">        <span class="comment">//jsonWithNewFlagDS.print();</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6、分流，使用ProcessFunction将ODS数据拆分成启动、曝光以及页面数据</span></span><br><span class="line">        SingleOutputStreamOperator&lt;String&gt; pageDS = jsonWithNewFlagDS.process(<span class="keyword">new</span> SpiltProcessFunc());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 7、将三个流的数据写入到对应的Kafka主题</span></span><br><span class="line">        DataStream&lt;String&gt; startDS = pageDS.getSideOutput(<span class="keyword">new</span> OutputTag&lt;String&gt;(<span class="string">"start"</span>) {</span><br><span class="line">        });</span><br><span class="line">        DataStream&lt;String&gt; displayDS = pageDS.getSideOutput(<span class="keyword">new</span> OutputTag&lt;String&gt;(<span class="string">"display"</span>) {</span><br><span class="line">        });</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 打印测试</span></span><br><span class="line">        <span class="comment">//pageDS.print("page &gt;&gt;&gt;&gt;&gt;&gt;&gt; ");</span></span><br><span class="line">        <span class="comment">//startDS.print("start &gt;&gt;&gt;&gt;&gt;&gt;&gt; ");</span></span><br><span class="line">        <span class="comment">//displayDS.print("display &gt;&gt;&gt;&gt;&gt;&gt;&gt; ");</span></span><br><span class="line"></span><br><span class="line">        pageDS.addSink(MyKafkaUtil.getKafkaSink(<span class="string">"dwd_page_log"</span>));</span><br><span class="line">        startDS.addSink(MyKafkaUtil.getKafkaSink(<span class="string">"dwd_start_log"</span>));</span><br><span class="line">        displayDS.addSink(MyKafkaUtil.getKafkaSink(<span class="string">"dwd_display_log"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 8、执行任务</span></span><br><span class="line">        env.execute(<span class="string">"read kafka source write kafka topic ... "</span>);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 做一个字段的校验</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">NewMidRichMapFunc</span> <span class="keyword">extends</span> <span class="title">RichMapFunction</span>&lt;<span class="title">JSONObject</span>,<span class="title">JSONObject</span>&gt; </span>{</span><br><span class="line">        <span class="comment">// 声明状态，用于表示当前mid是否以及访问过</span></span><br><span class="line">        <span class="keyword">private</span> ValueState&lt;String&gt; firstVisitDateState;</span><br><span class="line">        <span class="keyword">private</span> SimpleDateFormat simpleDateFormat;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>{</span><br><span class="line">            firstVisitDateState = getRuntimeContext().getState(<span class="keyword">new</span> ValueStateDescriptor&lt;String&gt;(<span class="string">"new-mid"</span>, String.class));</span><br><span class="line">            simpleDateFormat = <span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyy-MM-dd"</span>);</span><br><span class="line">        }</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> JSONObject <span class="title">map</span><span class="params">(JSONObject value)</span> <span class="keyword">throws</span> Exception </span>{</span><br><span class="line">            <span class="comment">// 取出新用户标记</span></span><br><span class="line">            String isNew = value.getJSONObject(<span class="string">"common"</span>).getString(<span class="string">"is_new"</span>);</span><br><span class="line">            <span class="comment">// 如果当前前端传输数据表示为新用户，则进行校验</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="string">"1"</span>.equals(isNew)) {</span><br><span class="line">                <span class="comment">// 取出状态数据，并取出当前访问时间</span></span><br><span class="line">                String firstDate = firstVisitDateState.value();</span><br><span class="line">                Long ts = value.getLong(<span class="string">"ts"</span>);</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 判断状态数据是否为null</span></span><br><span class="line">                <span class="keyword">if</span> (firstDate != <span class="keyword">null</span>) {</span><br><span class="line">                    <span class="comment">// 修复</span></span><br><span class="line">                    value.getJSONObject(<span class="string">"common"</span>).put(<span class="string">"is_new"</span>, <span class="number">0</span>);</span><br><span class="line">                } <span class="keyword">else</span> {</span><br><span class="line">                    <span class="comment">// 更新数据</span></span><br><span class="line">                    firstVisitDateState.update(simpleDateFormat.format(ts));</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">            <span class="keyword">return</span> value;</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将数据分流到kafka中</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SpiltProcessFunc</span> <span class="keyword">extends</span> <span class="title">ProcessFunction</span>&lt;<span class="title">JSONObject</span>,<span class="title">String</span>&gt;</span>{</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(JSONObject value, Context ctx, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception </span>{</span><br><span class="line">            <span class="comment">// 提前"start字段"</span></span><br><span class="line">            String startStr = value.getString(<span class="string">"start"</span>);</span><br><span class="line">            <span class="comment">// 判断是否为启动数据</span></span><br><span class="line">            <span class="keyword">if</span> (startStr != <span class="keyword">null</span> &amp;&amp; startStr.length() &gt; <span class="number">0</span>) {</span><br><span class="line">                <span class="comment">// 将启动日志输出到侧输出流</span></span><br><span class="line">                ctx.output(<span class="keyword">new</span> OutputTag&lt;String&gt;(<span class="string">"start"</span>){}, value.toString());</span><br><span class="line">            } <span class="keyword">else</span> {</span><br><span class="line">                <span class="comment">// 不是启动日志，继续判断是否是曝光数据</span></span><br><span class="line">                JSONArray displays = value.getJSONArray(<span class="string">"displays"</span>);</span><br><span class="line">                <span class="keyword">if</span> (displays != <span class="keyword">null</span> &amp;&amp; displays.size() &gt; <span class="number">0</span>) {</span><br><span class="line">                    <span class="comment">// 曝光数据，是一个数组类型的，遍历写入侧输出流</span></span><br><span class="line">                    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; displays.size(); i++) {</span><br><span class="line">                        <span class="comment">// 取出单条曝光数据</span></span><br><span class="line">                        JSONObject displayJson = displays.getJSONObject(i);</span><br><span class="line">                        <span class="comment">// 添加页面ID</span></span><br><span class="line">                        displayJson.put(<span class="string">"page_id"</span>, value.getJSONObject(<span class="string">"page"</span>).getString(<span class="string">"page_id"</span>));</span><br><span class="line">                        <span class="comment">// 输出到侧输出流中</span></span><br><span class="line">                        ctx.output(<span class="keyword">new</span> OutputTag&lt;String&gt;(<span class="string">"display"</span>){}, displayJson.toString());</span><br><span class="line">                    }</span><br><span class="line">                } <span class="keyword">else</span> {</span><br><span class="line">                    <span class="comment">// 页面数据，将数据输出到主流，主流使用collect</span></span><br><span class="line">                    out.collect(value.toString());</span><br><span class="line">                }</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

<h5 id="1-7-2-MyKafkaUtil"><a href="#1-7-2-MyKafkaUtil" class="headerlink" title="1.7.2 MyKafkaUtil"></a>1.7.2 MyKafkaUtil</h5><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wmy.flink.warehourse.utils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.serialization.SimpleStringSchema;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaProducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName:MyKafkaUtil</span></span><br><span class="line"><span class="comment"> * Package:com.wmy.flink.warehourse.utils</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span>:2021/7/13 16:46</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>:数仓开发工程师</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@email</span>:2647716549@qq.com</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>: kafka消费者的工具类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyKafkaUtil</span> </span>{</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> String KAFKA_SERVER = <span class="string">"yaxin01:9092,yaxin02:9092,yaxin03:9092"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> {</span><br><span class="line">        props.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, KAFKA_SERVER);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获取Kafka Source的方法</span></span><br><span class="line"><span class="comment">     * FlinkKafkaConsumer ---&gt; FlinkKafkaConsumerBase ---&gt; RichParallelSourceFunction</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> topic</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> groupID</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> FlinkKafkaConsumer&lt;String&gt; <span class="title">getKafkaSource</span><span class="params">(String topic,String groupID)</span> </span>{</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1、配置kafka消费参数</span></span><br><span class="line">        props.setProperty(ConsumerConfig.GROUP_ID_CONFIG, groupID);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2、获取kafkaSource</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> FlinkKafkaConsumer&lt;String&gt;(topic, <span class="keyword">new</span> SimpleStringSchema(), props);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> FlinkKafkaProducer&lt;String&gt; <span class="title">getKafkaSink</span><span class="params">(String topic)</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> FlinkKafkaProducer&lt;String&gt;(topic, <span class="keyword">new</span> SimpleStringSchema(), props);</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">}</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

<h5 id="1-7-3-测试数据"><a href="#1-7-3-测试数据" class="headerlink" title="1.7.3 测试数据"></a>1.7.3 测试数据</h5><figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-- 启动日志</span><br><span class="line">{<span class="attr">"common"</span>:{<span class="attr">"ar"</span>:<span class="string">"310000"</span>,<span class="attr">"ba"</span>:<span class="string">"Xiaomi"</span>,<span class="attr">"ch"</span>:<span class="string">"xiaomi"</span>,<span class="attr">"md"</span>:<span class="string">"Xiaomi 10 Pro "</span>,<span class="attr">"mid"</span>:<span class="string">"mid_7"</span>,<span class="attr">"os"</span>:<span class="string">"Android 10.0"</span>,<span class="attr">"uid"</span>:<span class="string">"177"</span>,<span class="attr">"vc"</span>:<span class="string">"v2.1.134"</span>},<span class="attr">"start"</span>:{<span class="attr">"entry"</span>:<span class="string">"icon"</span>,<span class="attr">"loading_time"</span>:<span class="number">15351</span>,<span class="attr">"open_ad_id"</span>:<span class="number">19</span>,<span class="attr">"open_ad_ms"</span>:<span class="number">8660</span>,<span class="attr">"open_ad_skip_ms"</span>:<span class="number">0</span>},<span class="attr">"ts"</span>:<span class="number">1592179997000</span>}</span><br><span class="line"></span><br><span class="line">-- 曝光数据</span><br><span class="line">{<span class="attr">"common"</span>:{<span class="attr">"ar"</span>:<span class="string">"310000"</span>,<span class="attr">"ba"</span>:<span class="string">"Xiaomi"</span>,<span class="attr">"ch"</span>:<span class="string">"xiaomi"</span>,<span class="attr">"md"</span>:<span class="string">"Xiaomi 10 Pro "</span>,<span class="attr">"mid"</span>:<span class="string">"mid_7"</span>,<span class="attr">"os"</span>:<span class="string">"Android 10.0"</span>,<span class="attr">"uid"</span>:<span class="string">"177"</span>,<span class="attr">"vc"</span>:<span class="string">"v2.1.134"</span>},<span class="attr">"displays"</span>:[{<span class="attr">"display_type"</span>:<span class="string">"activity"</span>,<span class="attr">"item"</span>:<span class="string">"2"</span>,<span class="attr">"item_type"</span>:<span class="string">"activity_id"</span>,<span class="attr">"order"</span>:<span class="number">1</span>},{<span class="attr">"display_type"</span>:<span class="string">"promotion"</span>,<span class="attr">"item"</span>:<span class="string">"9"</span>,<span class="attr">"item_type"</span>:<span class="string">"sku_id"</span>,<span class="attr">"order"</span>:<span class="number">2</span>},{<span class="attr">"display_type"</span>:<span class="string">"promotion"</span>,<span class="attr">"item"</span>:<span class="string">"7"</span>,<span class="attr">"item_type"</span>:<span class="string">"sku_id"</span>,<span class="attr">"order"</span>:<span class="number">3</span>},{<span class="attr">"display_type"</span>:<span class="string">"promotion"</span>,<span class="attr">"item"</span>:<span class="string">"9"</span>,<span class="attr">"item_type"</span>:<span class="string">"sku_id"</span>,<span class="attr">"order"</span>:<span class="number">4</span>},{<span class="attr">"display_type"</span>:<span class="string">"recommend"</span>,<span class="attr">"item"</span>:<span class="string">"1"</span>,<span class="attr">"item_type"</span>:<span class="string">"sku_id"</span>,<span class="attr">"order"</span>:<span class="number">5</span>},{<span class="attr">"display_type"</span>:<span class="string">"query"</span>,<span class="attr">"item"</span>:<span class="string">"8"</span>,<span class="attr">"item_type"</span>:<span class="string">"sku_id"</span>,<span class="attr">"order"</span>:<span class="number">6</span>}],<span class="attr">"page"</span>:{<span class="attr">"during_time"</span>:<span class="number">18532</span>,<span class="attr">"page_id"</span>:<span class="string">"home"</span>},<span class="attr">"ts"</span>:<span class="number">1592180012351</span>}</span><br><span class="line"></span><br><span class="line">-- 页面数据</span><br><span class="line">{<span class="attr">"common"</span>:{<span class="attr">"ar"</span>:<span class="string">"310000"</span>,<span class="attr">"ba"</span>:<span class="string">"Xiaomi"</span>,<span class="attr">"ch"</span>:<span class="string">"xiaomi"</span>,<span class="attr">"md"</span>:<span class="string">"Xiaomi 10 Pro "</span>,<span class="attr">"mid"</span>:<span class="string">"mid_7"</span>,<span class="attr">"os"</span>:<span class="string">"Android 10.0"</span>,<span class="attr">"uid"</span>:<span class="string">"177"</span>,<span class="attr">"vc"</span>:<span class="string">"v2.1.134"</span>},<span class="attr">"page"</span>:{<span class="attr">"during_time"</span>:<span class="number">19041</span>,<span class="attr">"item"</span>:<span class="string">"联想"</span>,<span class="attr">"item_type"</span>:<span class="string">"keyword"</span>,<span class="attr">"last_page_id"</span>:<span class="string">"home"</span>,<span class="attr">"page_id"</span>:<span class="string">"good_list"</span>},<span class="attr">"ts"</span>:<span class="number">1592180030883</span>}</span><br></pre></td></tr></tbody></table></figure>

<h5 id="1-7-4-展示结果"><a href="#1-7-4-展示结果" class="headerlink" title="1.7.4 展示结果"></a>1.7.4 展示结果</h5><p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210713194135844.png" alt="结果展示"></p>
<h4 id="1-8-测试问题说明"><a href="#1-8-测试问题说明" class="headerlink" title="1.8 测试问题说明"></a>1.8 测试问题说明</h4><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">checkpoint：出现异常就会自动重启</span></span><br><span class="line"></span><br><span class="line"><span class="attr">就是如果出现了脏数据的情况下或者解析数据失败，并不会立即的退出程序，而是处于无限的循环的状态</span></span><br><span class="line"><span class="attr">所以我们为了要保证集群的稳定性，最好是要设置重启失败的策略</span></span><br><span class="line"></span><br><span class="line"><span class="meta">官网地址：https</span>:<span class="string">//ci.apache.org/projects/flink/flink-docs-release-1.13/docs/deployment/config/</span></span><br><span class="line"></span><br><span class="line"><span class="attr">和重启策略有关系</span></span><br><span class="line"><span class="meta">env.setRestartStrategy(RestartStrategies.fixedDelayRestart(3,</span> <span class="string">Time.seconds(1)));</span></span><br><span class="line"></span><br><span class="line"><span class="attr">在实际生成中最好都是要开启状态后端，checkpoint和重启策略的</span></span><br><span class="line"><span class="attr">env.setRestartStrategy(RestartStrategies.noRestart());</span></span><br><span class="line"></span><br><span class="line"><span class="attr">我们可以捕获异常，这样把脏数据给过滤掉</span></span><br><span class="line"></span><br><span class="line"><span class="attr">也可以看一个脏数据的比例和分析脏数据的缘由来提升程序的健壮性</span></span><br></pre></td></tr></tbody></table></figure>

<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210713200208957.png" alt="官网介绍重启策略"></p>
<h3 id="2、DWD层（行为数据-整体测试）"><a href="#2、DWD层（行为数据-整体测试）" class="headerlink" title="2、DWD层（行为数据 整体测试）"></a>2、DWD层（行为数据 整体测试）</h3><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">日志数据DWD层测试所需进程</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Mock、Nginx、Logger、Kafka(ZK)、Flink_APP(HDFS\kafka)、三台消费者</span></span><br><span class="line"></span><br><span class="line"><span class="attr">dwd_page_log</span></span><br><span class="line"><span class="attr">dwd_start_log</span></span><br><span class="line"><span class="attr">dwd_display_log</span></span><br><span class="line"></span><br><span class="line"><span class="attr">主要是读取kafka数据进行，然后在进行分流</span></span><br></pre></td></tr></tbody></table></figure>

<h2 id="DWD层-业务数据"><a href="#DWD层-业务数据" class="headerlink" title="DWD层-业务数据"></a>DWD层-业务数据</h2><h3 id="需求说明"><a href="#需求说明" class="headerlink" title="需求说明"></a>需求说明</h3><h4 id="1、业务说明"><a href="#1、业务说明" class="headerlink" title="1、业务说明"></a>1、业务说明</h4><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">业务数据得变化，我们可以通过MaxWell采集到，但是MaxWell是把全部数据统一写入一个topic中，这些数据包括业务数据，也包括维度数据，这样显然不利于日后得数据处理，所以这个功能是从kafka得业务数据ODS层读取数据，经过处理后，将维度数据保存到HBASE，将事实数据写回kafka作为业务数据得DWD层</span></span><br></pre></td></tr></tbody></table></figure>

<h4 id="2、接收kafka数据，过滤空值数据"><a href="#2、接收kafka数据，过滤空值数据" class="headerlink" title="2、接收kafka数据，过滤空值数据"></a>2、接收kafka数据，过滤空值数据</h4><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">对maxwell抓取数据进行ETL，有用得部分保留，没有用得部分过滤掉</span></span><br></pre></td></tr></tbody></table></figure>

<h4 id="3、实现动态分流"><a href="#3、实现动态分流" class="headerlink" title="3、实现动态分流"></a>3、实现动态分流</h4><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">由于MaxWell是把全部数据统一写入一个topic中，这样显然不利于日后的数据处理，所以需要把各个表拆开处理，但是由于每个表有不同的特点，有些表是维度表，有些表是事实表，有些表既是事实表在某种情况下又是维度表。</span></span><br><span class="line"><span class="attr">在实时计算中一般把维度数据写入一个存储容器中，一般是方便通过主键查询的数据库比如HBASE\REDIS\MYSQL等，一般把事实表写入流中，进行进一步处理，最终形成宽表，但是作为Flink事实计算任务，如何得知那些表是维度表，那些是事实表，而这些表又应该采集那些字段勒？</span></span><br><span class="line"><span class="attr">这样的配置不是和写在配置文件中，因为这样的花，业务端随着雪球变化每增加一张表</span></span><br><span class="line"></span><br><span class="line"><span class="attr">使用配置表的方式是可以不用停机操作的，配置文件中必须是一个外部的配置文件，而且还需要每隔一段时间就必须要去访问一次，否则万一出现数据的变更，我们使用的是MySQL来进行存储配置数据表，用来加载配置信息，配置信息还不能写死，代码中还必须使用一个定时任务，Spark源码中，master以一个固定的时间来进行校验worker是否超时</span></span><br></pre></td></tr></tbody></table></figure>

<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210714103610400.png" alt="如何实现动态分流"></p>
<h4 id="4、把分好的流保存到对应表、主题中"><a href="#4、把分好的流保存到对应表、主题中" class="headerlink" title="4、把分好的流保存到对应表、主题中"></a>4、把分好的流保存到对应表、主题中</h4><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">1、业务数据保存到Kafka主题中</span></span><br><span class="line"><span class="attr">2、维度数据保存到HBASE的表中</span></span><br></pre></td></tr></tbody></table></figure>

<h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><h4 id="1、接收kafka数据，过滤空值数据"><a href="#1、接收kafka数据，过滤空值数据" class="headerlink" title="1、接收kafka数据，过滤空值数据"></a>1、接收kafka数据，过滤空值数据</h4><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wmy.flink.warehourse.app.dwd;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSON;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONObject;</span><br><span class="line"><span class="keyword">import</span> com.wmy.flink.warehourse.utils.MyKafkaUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.functions.FilterFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.restartstrategy.RestartStrategies;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.time.Time;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.runtime.executiongraph.restart.RestartStrategy;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.runtime.state.filesystem.FsStateBackend;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.CheckpointingMode;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName:DbBaseApp</span></span><br><span class="line"><span class="comment"> * Package:com.wmy.flink.warehourse.app.dwd</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span>:2021/7/14 10:07</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>:数仓开发工程师</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@email</span>:2647716549@qq.com</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>: 分析业务数据</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DbBaseApp</span> </span>{</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>{</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1、获取执行环境</span></span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1.1 checkpointn</span></span><br><span class="line">        <span class="comment">//env.setStateBackend(new FsStateBackend("hdfs://yaxin01:9820/flink-realtime-warehourse/dwd"));</span></span><br><span class="line">        <span class="comment">//env.enableCheckpointing(1000L, CheckpointingMode.EXACTLY_ONCE);</span></span><br><span class="line">        <span class="comment">//env.getCheckpointConfig().setCheckpointTimeout(60000L);</span></span><br><span class="line">        <span class="comment">//env.setRestartStrategy(RestartStrategies.fixedDelayRestart(3, Time.seconds(3)));</span></span><br><span class="line">        <span class="comment">//env.setRestartStrategy(RestartStrategies.noRestart());</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2、读取Kafka数据</span></span><br><span class="line">        FlinkKafkaConsumer&lt;String&gt; kafkaSource = MyKafkaUtil.getKafkaSource(<span class="string">"ods_base_db_m"</span>, <span class="string">"ods_db_group"</span>);</span><br><span class="line">        DataStreamSource&lt;String&gt; kafkaDS = env.addSource(kafkaSource);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3、将每行数据转换为JSON对象</span></span><br><span class="line">        SingleOutputStreamOperator&lt;JSONObject&gt; jsonObjDS = kafkaDS.map(JSON::parseObject);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4、过滤</span></span><br><span class="line">        SingleOutputStreamOperator&lt;JSONObject&gt; filterDS = jsonObjDS.filter(<span class="keyword">new</span> FilterFunction&lt;JSONObject&gt;() {</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">filter</span><span class="params">(JSONObject value)</span> <span class="keyword">throws</span> Exception </span>{</span><br><span class="line">                <span class="comment">// 获取一个data字段{"data":{"id":30,"user_name":"zhangsan","tel":"19845368388"}}</span></span><br><span class="line">                String data = value.getString(<span class="string">"data"</span>);</span><br><span class="line">                <span class="keyword">return</span> data != <span class="keyword">null</span> &amp;&amp; data.length() &gt; <span class="number">0</span>;</span><br><span class="line">            }</span><br><span class="line">        });</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 打印测试</span></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 测试说明，由于我没有采集那些的数据，没有实时采集MySQL中的数据到kafka中，所以我是直接生产到kafka中</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * 数据：</span></span><br><span class="line"><span class="comment">         * {"database":"gmall","xid":111,"data":{"id":30,"user_name":"zhangsan","tel":"19845368388"}}</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        filterDS.print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 5、分流，ProcessFunction，如果使用状态的可以使用复合函数</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 6、取出分流输出将数据写入kafka或者phonix</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 7、执行任务</span></span><br><span class="line">        env.execute(<span class="string">"DbBaseApp &gt;&gt;&gt;&gt;&gt;&gt;&gt; "</span>);</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>

<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210714103832864.png" alt="数据生产"></p>
<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210714103846987.png" alt="结果展示"></p>
<h4 id="2、根据MySQL的配置，实现动态分流"><a href="#2、根据MySQL的配置，实现动态分流" class="headerlink" title="2、根据MySQL的配置，实现动态分流"></a>2、根据MySQL的配置，实现动态分流</h4><h5 id="2-1-MySQL配置表的创建"><a href="#2-1-MySQL配置表的创建" class="headerlink" title="2.1 MySQL配置表的创建"></a>2.1 MySQL配置表的创建</h5><figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> `table_process`(</span><br><span class="line">`source_table` <span class="type">varchar</span>(<span class="number">200</span>) <span class="keyword">not</span> <span class="keyword">null</span> comment <span class="string">'来源表'</span>,</span><br><span class="line">`operate_type` <span class="type">varchar</span>(<span class="number">200</span>) <span class="keyword">not</span> <span class="keyword">null</span> comment <span class="string">'操作类型 insert,update,delete'</span>,</span><br><span class="line">`sink_type` <span class="type">varchar</span>(<span class="number">200</span>) <span class="keyword">default</span> <span class="keyword">null</span> comment <span class="string">'输出类型 hbase kafka'</span>,</span><br><span class="line">`sink_table` <span class="type">varchar</span>(<span class="number">200</span>) <span class="keyword">default</span> <span class="keyword">null</span> comment <span class="string">'输出表（主题）'</span>,</span><br><span class="line">`sink_columns` <span class="type">varchar</span>(<span class="number">200</span>) <span class="keyword">default</span> <span class="keyword">null</span> comment <span class="string">'输出字段'</span>,</span><br><span class="line">`sink_pk` <span class="type">varchar</span>(<span class="number">200</span>) <span class="keyword">default</span> <span class="keyword">null</span> comment <span class="string">'主键字段'</span>,</span><br><span class="line">`sink_extend` <span class="type">varchar</span>(<span class="number">200</span>) <span class="keyword">default</span> <span class="keyword">null</span> comment <span class="string">'建表扩展'</span>,</span><br><span class="line"><span class="keyword">primary</span> key (`source_table`,`operate_type`)</span><br><span class="line">)engine<span class="operator">=</span>InnoDB <span class="keyword">default</span> charset<span class="operator">=</span>utf8;</span><br></pre></td></tr></tbody></table></figure>

<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210714104619292.png" alt="表的字段设置类型"></p>
<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210714104635768.png" alt="查看表结构"></p>
<h5 id="2-2-程序流程分析"><a href="#2-2-程序流程分析" class="headerlink" title="2.2 程序流程分析"></a>2.2 程序流程分析</h5><p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210715165318028.png" alt="程序流程分析"></p>
<figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">open</span>:<span class="string"></span></span><br><span class="line">	<span class="attr">获取数据，如果只是调用一次的，这样的话动态分流就完成不了，停机重启，需要开启一个周期调度任务，这个需要放到open方法里面，open生命周期方法，查询一个配置表（MySQL）</span></span><br><span class="line">	</span><br><span class="line"><span class="attr">hbase/kafka：</span></span><br><span class="line">	<span class="attr">这个主要是看MySQL中的配置信息，如果单条数据</span></span><br><span class="line">	</span><br><span class="line"><span class="meta">checkTable：</span>	<span class="string"></span></span><br><span class="line">	<span class="attr">不需要自己去phoenix，去创建表，是让系统给我们自己去创建表，这样我就不需要一个扩展字段，不存在就创建，存在的话就不创建，跟配置信息MySQL的表相关</span></span><br><span class="line">	</span><br><span class="line"><span class="attr">filterColumn：</span></span><br><span class="line">	<span class="attr">删除一些不需要的字段，到底是要往哪里去写</span></span><br><span class="line">	</span><br><span class="line"><span class="attr">应该是先读取一次性配置信息，然后才开始周期性的去读取这个配置信息</span></span><br><span class="line"></span><br><span class="line"><span class="attr">需要检查并建表</span></span><br><span class="line"></span><br><span class="line"><span class="attr">同步然后在封装在map中，如果这是一个新增的维度信息，感觉把这个表给建立一下</span></span><br><span class="line"><span class="attr">processelement读取配置信息过滤字段，将我们的信息给分流</span></span><br></pre></td></tr></tbody></table></figure>

<h5 id="2-3-程序的测试"><a href="#2-3-程序的测试" class="headerlink" title="2.3 程序的测试"></a>2.3 程序的测试</h5><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">动态获取配置信息以及创建Phoenix测试流程</span></span><br><span class="line"><span class="attr">因为目前我是确实业务数据到kafka这个流程，我直接就是生产到kafka中</span></span><br><span class="line"><span class="attr">进程：zk,kafka,hadoop,hbase,phoenix,</span></span><br><span class="line"></span><br><span class="line"><span class="attr">如果有的同步机制的话，我们是直接在MySQL当中采用binlog日志来进行</span></span><br><span class="line"></span><br><span class="line"><span class="attr">现在我是直接模拟生成最后采集的那个json数据，这些都是手动写的</span></span><br><span class="line"></span><br><span class="line"><span class="attr">需要开启Kafka生成者</span></span><br></pre></td></tr></tbody></table></figure>

<h6 id="2-3-1-模拟同步的日志"><a href="#2-3-1-模拟同步的日志" class="headerlink" title="2.3.1 模拟同步的日志"></a>2.3.1 模拟同步的日志</h6><figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">{<span class="attr">"database"</span>:<span class="string">"gmall"</span>,<span class="attr">"xid"</span>:<span class="number">305</span>,<span class="attr">"data"</span>:{<span class="attr">"tm_name"</span>:<span class="string">"vivo"</span>,<span class="attr">"log_url"</span>:<span class="string">"https://item.jd.com/100009989503.html"</span>,<span class="attr">"id"</span>:<span class="string">"13"</span>},<span class="attr">"commit"</span>:<span class="literal">true</span>,<span class="attr">"type"</span>:<span class="string">"delete"</span>,<span class="attr">"table"</span>:<span class="string">"base_trademark"</span>,<span class="attr">"ts"</span>:<span class="number">1626346291</span>}</span><br></pre></td></tr></tbody></table></figure>

<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210715221400883.png" alt="结果展示"></p>
<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210715221420898.png" alt="phoenix展示"></p>
<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210716001234182.png" alt="展示结果"></p>
<figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">注意：这个是我们在更新数据库中得东西得时候，主键必须是一致得，否则会报错得，要不然就不会出现结果了</span></span><br></pre></td></tr></tbody></table></figure>

<h4 id="3、分流维度数据到HBASE中"><a href="#3、分流维度数据到HBASE中" class="headerlink" title="3、分流维度数据到HBASE中"></a>3、分流维度数据到HBASE中</h4><figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">{<span class="attr">"database"</span>:<span class="string">"gmall"</span>,<span class="attr">"xid"</span>:<span class="number">5520</span>,<span class="attr">"data"</span>:{<span class="attr">"id"</span>:<span class="string">"28"</span>,<span class="attr">"tm_name"</span>:<span class="string">"vivo"</span>,<span class="attr">"log_url"</span>:<span class="string">"https://item.jd.com/100009989503.html"</span>},<span class="attr">"commit"</span>:<span class="literal">true</span>,<span class="attr">"type"</span>:<span class="string">"insert"</span>,<span class="attr">"table"</span>:<span class="string">"aa"</span>,<span class="attr">"ts"</span>:<span class="number">1626346292</span>}</span><br></pre></td></tr></tbody></table></figure>

<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210717103020503.png" alt="MySQL配置信息"></p>
<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210717102951981.png" alt="idea显示结果"></p>
<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210717103140907.png" alt="hbase中的数据"></p>
<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210717103349917.png" alt="动态添加的过程"></p>
<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210717103411066.png" alt="hbase中的数据"></p>
<h4 id="4、分流事实数据到Kafka中"><a href="#4、分流事实数据到Kafka中" class="headerlink" title="4、分流事实数据到Kafka中"></a>4、分流事实数据到Kafka中</h4><figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hbase:</span><br><span class="line"></span><br><span class="line">{<span class="attr">"database"</span>:<span class="string">"gmall"</span>,<span class="attr">"xid"</span>:<span class="number">5520</span>,<span class="attr">"data"</span>:{<span class="attr">"id"</span>:<span class="string">"28"</span>,<span class="attr">"tm_name"</span>:<span class="string">"vivo"</span>,<span class="attr">"log_url"</span>:<span class="string">"https://item.jd.com/100009989503.html"</span>},<span class="attr">"commit"</span>:<span class="literal">true</span>,<span class="attr">"type"</span>:<span class="string">"insert"</span>,<span class="attr">"table"</span>:<span class="string">"aa"</span>,<span class="attr">"ts"</span>:<span class="number">1626346292</span>}</span><br><span class="line"></span><br><span class="line">{<span class="attr">"database"</span>:<span class="string">"gmall"</span>,<span class="attr">"xid"</span>:<span class="number">5520</span>,<span class="attr">"data"</span>:{<span class="attr">"id"</span>:<span class="string">"30"</span>,<span class="attr">"tm_name"</span>:<span class="string">"vivo"</span>,<span class="attr">"log_url"</span>:<span class="string">"https://item.jd.com/100009989503.html"</span>},<span class="attr">"commit"</span>:<span class="literal">true</span>,<span class="attr">"type"</span>:<span class="string">"insert"</span>,<span class="attr">"table"</span>:<span class="string">"bb"</span>,<span class="attr">"ts"</span>:<span class="number">1626346292</span>}</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kafka:</span><br><span class="line"></span><br><span class="line">{<span class="attr">"database"</span>:<span class="string">"gmall"</span>,<span class="attr">"xid"</span>:<span class="number">305</span>,<span class="attr">"data"</span>:{<span class="attr">"tm_name"</span>:<span class="string">"vivo"</span>,<span class="attr">"log_url"</span>:<span class="string">"https://item.jd.com/100009989503.html"</span>,<span class="attr">"id"</span>:<span class="string">"31"</span>},<span class="attr">"commit"</span>:<span class="literal">true</span>,<span class="attr">"type"</span>:<span class="string">"insert"</span>,<span class="attr">"table"</span>:<span class="string">"cc"</span>,<span class="attr">"ts"</span>:<span class="number">1626346291</span>}</span><br></pre></td></tr></tbody></table></figure>

<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210717104914665.png" alt="MySQL配置信息"></p>
<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210717104938363.png" alt="idea显示结果"></p>
<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210717104956193.png" alt="消费Kafka中的数据"></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210714162801543.png" alt="image-20210714162801543"></p>
<h4 id="1、完整代码可以去看博客"><a href="#1、完整代码可以去看博客" class="headerlink" title="1、完整代码可以去看博客"></a>1、完整代码可以去看博客</h4><h4 id="2、查看结果"><a href="#2、查看结果" class="headerlink" title="2、查看结果"></a>2、查看结果</h4><p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210717105120039.png" alt="hbase中的数据"></p>
<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210717105314749.png" alt="kafka topic"></p>
<h2 id="DWM"><a href="#DWM" class="headerlink" title="DWM"></a>DWM</h2><h3 id="1、Kafka精准一次性语义-注意事项"><a href="#1、Kafka精准一次性语义-注意事项" class="headerlink" title="1、Kafka精准一次性语义 注意事项"></a>1、Kafka精准一次性语义 注意事项</h3><p>DbBaseApp.java</p>
<figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">这个如果打开这个状态后端和checkpoint测试的话</span></span><br><span class="line"></span><br><span class="line"><span class="meta">env.setStateBackend(new</span> <span class="string">FsStateBackend("hdfs://yaxin01:9820/flink-realtime-warehourse/dwd"));</span></span><br><span class="line"><span class="meta">env.enableCheckpointing(1000L,</span> <span class="string">CheckpointingMode.EXACTLY_ONCE);</span></span><br><span class="line"><span class="attr">env.getCheckpointConfig().setCheckpointTimeout(60000L);</span></span><br><span class="line"><span class="meta">env.setRestartStrategy(RestartStrategies.fixedDelayRestart(3,</span> <span class="string">Time.seconds(3)));</span></span><br><span class="line"><span class="attr">env.setRestartStrategy(RestartStrategies.noRestart());</span></span><br><span class="line"></span><br><span class="line"><span class="attr">缺少一个包，会报一个错，hdfs-schema找不到</span></span><br><span class="line"><span class="attr">&lt;!--如果保存检查点到hdfs上，需要引入此依赖--&gt;</span></span><br><span class="line"><span class="attr">&lt;dependency&gt;</span></span><br><span class="line">    <span class="attr">&lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;</span></span><br><span class="line">    <span class="attr">&lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;</span></span><br><span class="line">    <span class="attr">&lt;version&gt;${hadoop.version}&lt;/version&gt;</span></span><br><span class="line"><span class="attr">&lt;/dependency&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">但是还是会报kafka的事务的超时时间太短了</span></span><br><span class="line"><span class="attr">数据源kafka，sink也是kafka，可以实现一个端到端的精准一次性，实现两阶段提交</span></span><br><span class="line"><span class="attr">到checkpoint真正完成提交去执行，然后才能真正的去执行，</span></span><br><span class="line"><span class="attr">在kafka中开启事务，这个事务也有自己的超时时间，这两个超时时间应该谁大一些</span></span><br><span class="line"><span class="attr">开启事务，预提交，来一条写一条</span></span><br><span class="line"><span class="attr">什么时候关闭，checkpoint完成,jobmanager通知才真正完成</span></span><br><span class="line"><span class="attr">checkpint</span> <span class="string">&gt; kafka 事务</span></span><br><span class="line"><span class="attr">如果checkpoint的时间大于kafka的事务的时间，kafka挂掉了，但是checkpoint成功了，事务失败了，回滚了，消费数据是从checkpoint之后开始消费，但是会数据丢失</span></span><br><span class="line"></span><br><span class="line"><span class="attr">checkpoint</span> <span class="string">&lt; kafka事务使劲啊</span></span><br><span class="line"><span class="meta">如果checkpoint失败了，事务回滚，没有问题，如果开启checkpoint，kafka</span> <span class="string">exactly once</span></span><br><span class="line"><span class="attr">这个时候要加一个参数</span></span><br><span class="line"><span class="attr">env.getCheckpointConfig().setCheckpointTimeout(60000L);</span></span><br><span class="line"></span><br><span class="line"><span class="attr">所以我们还得在flinkKafkaProducer中设置事务的时间</span></span><br><span class="line"><span class="attr">public</span> <span class="string">static &lt;T&gt; FlinkKafkaProducer&lt;T&gt; 							getKafkaSinkBySchema(KafkaSerializationSchema&lt;T&gt; kafkaSerializationSchema) {</span></span><br><span class="line">	<span class="meta">props.setProperty(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG,</span> <span class="string">5 * 60 * 1000L + "");</span></span><br><span class="line">	<span class="attr">return</span> <span class="string">new FlinkKafkaProducer&lt;T&gt;(DEFAULT_TOPIC, kafkaSerializationSchema, props, FlinkKafkaProducer.Semantic.EXACTLY_ONCE);</span></span><br><span class="line"><span class="attr">}</span></span><br><span class="line"></span><br><span class="line"><span class="meta">事务是根据checkpoint的结果来进行提交的,kafka</span> <span class="string">的事务时间要比kafka的 checkpoint的时间要大</span></span><br></pre></td></tr></tbody></table></figure>

<h3 id="2、分层思路"><a href="#2、分层思路" class="headerlink" title="2、分层思路"></a>2、分层思路</h3><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">ODS</span> <span class="string">---&gt; DWD ---&gt; DWM ---&gt; DWS ---&gt; ADS</span></span><br><span class="line"><span class="attr">越靠近ADS，越是要看需求，去拆分表的时候，没有太多的去考虑需求</span></span><br><span class="line"></span><br><span class="line"><span class="attr">业务数据，我们在配置信息的时候是需要考虑业务逻辑的</span></span><br><span class="line"><span class="attr">ODS</span> <span class="string">DWD 如何考虑维度建模，不是考虑最后做什么需求去建立的</span></span><br><span class="line"><span class="attr">MySQL在做维度退化的时候，表会少一点，星型模型</span></span><br><span class="line"></span><br><span class="line"><span class="attr">商品信息sku，spu，trademark合并</span></span><br><span class="line"><span class="attr">维度退化，表少了</span></span><br><span class="line"><span class="attr">维度建模，确定维度，根据维度选择度量值，度量是最后的需求，DWD按照维度来进行建立的</span></span><br><span class="line"><span class="attr">字段，还是有关系的，关系性不是那么强的</span></span><br><span class="line"></span><br><span class="line"><span class="attr">DWM做一个预处理，减少业务的复杂性，DWS可能会复用DWM层的表</span></span><br><span class="line"></span><br><span class="line"><span class="attr">实现方式不一样，分层思路是一样的</span></span><br><span class="line"></span><br><span class="line"><span class="attr">需求：</span></span><br><span class="line">	<span class="attr">访客　　　－－－＞　可视化大屏</span></span><br><span class="line">	<span class="meta">商品　　　－－－＞　可视化大屏</span> <span class="string">---&gt; 多维分析 | 可视化大屏 </span></span><br><span class="line">	<span class="attr">地区　　　－－－＞　可视化大屏</span></span><br><span class="line">	<span class="attr">关键词　　－－－＞　可视化大屏</span></span><br><span class="line"></span><br><span class="line"><span class="attr">ADS</span> <span class="string">需求：</span></span><br><span class="line">	<span class="attr">有一些需求不一定是来自DWS，也有可能来自DWD层</span></span><br><span class="line"></span><br><span class="line"><span class="attr">访客：</span></span><br><span class="line">	<span class="meta">PV：page_log</span> <span class="string">---&gt; dwd</span></span><br><span class="line">	<span class="meta">UV：page_log过滤去重</span> <span class="string">---&gt; dwm</span></span><br><span class="line">	<span class="meta">跳出率：page_log判定（离开平台）</span> <span class="string">---&gt; dwm</span></span><br><span class="line">	<span class="meta">进入页面数：识别开始访问</span> <span class="string">---&gt; dwd</span></span><br><span class="line">	<span class="meta">连续访问时长：page_log直接可求</span> <span class="string">---&gt; dwd</span></span><br><span class="line">	</span><br><span class="line"><span class="attr">商品：</span></span><br><span class="line">	<span class="attr">点赞、收藏、加购物车</span></span><br><span class="line">	<span class="meta">下单</span> <span class="string">---&gt; 可视化大屏 ---&gt; 订单宽表 ---&gt; dwm</span></span><br><span class="line">	</span><br><span class="line"><span class="attr">地区：</span></span><br><span class="line">	<span class="meta">下单</span> <span class="string">---&gt; 订单宽表  ---&gt; dwm</span></span><br><span class="line">	<span class="attr">订单宽表比支付宽表的话跟复杂</span></span><br><span class="line">	</span><br><span class="line"><span class="attr">关键词：</span></span><br><span class="line">	<span class="meta">搜索关键词</span>  <span class="string">---&gt; 页面访问日志、直接可求 ---&gt; dwd</span></span><br><span class="line">	<span class="meta">点击商品关键词</span> <span class="string">---&gt; 商品主题下单再次聚合 ---&gt; dws</span></span><br><span class="line">	<span class="meta">下单商品关键词</span> <span class="string">---&gt; 商品主题下单再次聚合 ---&gt; dws</span></span><br><span class="line">	</span><br><span class="line"><span class="attr">广告投放，手机APP付款的页面比较小</span></span><br><span class="line"><span class="attr">订单的跳出页面比较高，这个页面可能有问题，分析用户的付款率比较低，没有下单，支付，购物车</span></span><br><span class="line"><span class="attr">从那个页面跳出比较多，整个网页做的不好，用户详情页比较高，多多少少都有问题</span></span><br><span class="line"></span><br><span class="line"><span class="attr">营业额比较低</span></span><br><span class="line"><span class="attr">但是不知道细节，从销售渠道来进行分析，不同的定义，跳出率，引流和推广的跳出率</span></span><br><span class="line"><span class="attr">方式的不同，导致实现的方式不同，跳出数/总数</span></span><br><span class="line"><span class="attr">过滤的方式来求跳出数</span></span><br><span class="line"></span><br><span class="line"><span class="attr">中间层，并不是为了能够出指标，而是提供复用性</span></span><br><span class="line"></span><br><span class="line"><span class="attr">大屏看的都是地区名称，需要进行关联，订单宽表</span></span><br><span class="line"><span class="attr">DWM结合DWD在一次聚合得到一个聚合操作，Clickhouse可以按照SQL分析</span></span><br><span class="line"></span><br><span class="line"><span class="attr">业务计算：</span></span><br><span class="line">	<span class="attr">访问UV计算</span></span><br><span class="line">	<span class="attr">跳出明细计算</span></span><br><span class="line">	<span class="attr">订单宽表</span></span><br><span class="line">	<span class="attr">支付宽表</span></span><br></pre></td></tr></tbody></table></figure>

<h3 id="3、访客UV计算"><a href="#3、访客UV计算" class="headerlink" title="3、访客UV计算"></a>3、访客UV计算</h3><h4 id="3-1-业务说明"><a href="#3-1-业务说明" class="headerlink" title="3.1 业务说明"></a>3.1 业务说明</h4><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">UV，独立访客数，对于实时计算中，即每日活跃用户，因为实时计算中的UV是指当日的访客数</span></span><br><span class="line"><span class="attr">那么如何从用户行为日志中识别当日的访客数</span></span><br><span class="line"><span class="attr">1、识别访客打开第一个页面就进入我们的应用</span></span><br><span class="line"><span class="attr">2、访客一天中多次进入应用，我们要在一天范围内进行去重</span></span><br></pre></td></tr></tbody></table></figure>

<h4 id="3-2-从kafka的dwd-page-log主题接收数据"><a href="#3-2-从kafka的dwd-page-log主题接收数据" class="headerlink" title="3.2 从kafka的dwd_page_log主题接收数据"></a>3.2 从kafka的dwd_page_log主题接收数据</h4><h4 id="3-3-核心代码过滤"><a href="#3-3-核心代码过滤" class="headerlink" title="3.3 核心代码过滤"></a>3.3 核心代码过滤</h4><h4 id="3-4-过滤后的UV写到Kafka的DWM层中"><a href="#3-4-过滤后的UV写到Kafka的DWM层中" class="headerlink" title="3.4 过滤后的UV写到Kafka的DWM层中"></a>3.4 过滤后的UV写到Kafka的DWM层中</h4><h4 id="3-5-测试"><a href="#3-5-测试" class="headerlink" title="3.5 测试"></a>3.5 测试</h4><figure class="highlight json"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">{<span class="attr">"common"</span>:{<span class="attr">"ar"</span>:<span class="string">"310000"</span>,<span class="attr">"uid"</span>:<span class="string">"177"</span>,<span class="attr">"os"</span>:<span class="string">"Android 10.0"</span>,<span class="attr">"ch"</span>:<span class="string">"xiaomi"</span>,<span class="attr">"md"</span>:<span class="string">"Xiaomi 10 Pro "</span>,<span class="attr">"mid"</span>:<span class="string">"mid_8"</span>,<span class="attr">"vc"</span>:<span class="string">"v2.1.134"</span>,<span class="attr">"ba"</span>:<span class="string">"Xiaomi"</span>},<span class="attr">"page"</span>:{<span class="attr">"page_id"</span>:<span class="string">"good_list"</span>,<span class="attr">"item"</span>:<span class="string">"联想"</span>,<span class="attr">"during_time"</span>:<span class="number">19041</span>,<span class="attr">"item_type"</span>:<span class="string">"keyword"</span>,<span class="attr">"last_page_id"</span>:<span class="string">""</span>},<span class="attr">"ts"</span>:<span class="number">1592180030885</span>}</span><br><span class="line"></span><br><span class="line">{<span class="attr">"common"</span>:{<span class="attr">"ar"</span>:<span class="string">"310000"</span>,<span class="attr">"uid"</span>:<span class="string">"177"</span>,<span class="attr">"os"</span>:<span class="string">"Android 10.0"</span>,<span class="attr">"ch"</span>:<span class="string">"xiaomi"</span>,<span class="attr">"md"</span>:<span class="string">"Xiaomi 10 Pro "</span>,<span class="attr">"mid"</span>:<span class="string">"mid_9"</span>,<span class="attr">"vc"</span>:<span class="string">"v2.1.134"</span>,<span class="attr">"ba"</span>:<span class="string">"Xiaomi"</span>},<span class="attr">"page"</span>:{<span class="attr">"page_id"</span>:<span class="string">"good_list"</span>,<span class="attr">"item"</span>:<span class="string">"联想"</span>,<span class="attr">"during_time"</span>:<span class="number">19041</span>,<span class="attr">"item_type"</span>:<span class="string">"keyword"</span>,<span class="attr">"last_page_id"</span>:<span class="string">""</span>},<span class="attr">"ts"</span>:<span class="number">1592183630</span>}</span><br></pre></td></tr></tbody></table></figure>

<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210718084519474.png" alt="结果展示"></p>
<h3 id="４、跳出明细计算"><a href="#４、跳出明细计算" class="headerlink" title="４、跳出明细计算"></a>４、跳出明细计算</h3><p>Flink使用CEP来进行复杂事件的处理</p>
<h3 id="５、订单宽表"><a href="#５、订单宽表" class="headerlink" title="５、订单宽表"></a>５、订单宽表</h3><h4 id="5-1-双流Join-Interval"><a href="#5-1-双流Join-Interval" class="headerlink" title="5.1 双流Join Interval"></a>5.1 双流Join Interval</h4><figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wmy.flink.warehourse.app.dwm;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSON;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONObject;</span><br><span class="line"><span class="keyword">import</span> com.wmy.flink.warehourse.bean.OrderDetail;</span><br><span class="line"><span class="keyword">import</span> com.wmy.flink.warehourse.bean.OrderInfo;</span><br><span class="line"><span class="keyword">import</span> com.wmy.flink.warehourse.bean.OrderWide;</span><br><span class="line"><span class="keyword">import</span> com.wmy.flink.warehourse.utils.MyKafkaUtil;</span><br><span class="line"><span class="keyword">import</span> org.apache.avro.Schema;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.eventtime.SerializableTimestampAssigner;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.eventtime.WatermarkStrategy;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.runtime.state.filesystem.FsStateBackend;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.CheckpointingMode;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStreamSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.KeyedStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.co.ProcessJoinFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.Time;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.text.SimpleDateFormat;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName:OrderWideApp</span></span><br><span class="line"><span class="comment"> * Package:com.wmy.flink.warehourse.app.dwm</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span>:2021/7/20 9:15</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>:数仓开发工程师</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@email</span>:wmy_2000@163.com</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>:</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderWideApp</span> </span>{</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>{</span><br><span class="line">        <span class="comment">// 1、获取执行环境</span></span><br><span class="line">        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line">        env.setParallelism(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1.1 设置状态后端</span></span><br><span class="line">        env.getCheckpointConfig().setCheckpointStorage(<span class="string">"hdfs://yaxin01:9820/flink-realtime-warehourse/dwd_log/ck"</span>);</span><br><span class="line">        env.enableCheckpointing(<span class="number">10000L</span>, CheckpointingMode.EXACTLY_ONCE);</span><br><span class="line">        env.getCheckpointConfig().setCheckpointTimeout(<span class="number">60000L</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2、读取kafka订单和订单明细主题数据 dwd_order_info dwd_order_detail</span></span><br><span class="line">        String orderInfoSourceTopic = <span class="string">"dwd_order_info"</span>;</span><br><span class="line">        String orderDetailSourceTopic = <span class="string">"dwd_order_detail"</span>;</span><br><span class="line">        String orderWideSinkTopic = <span class="string">"dwm_order_wide"</span>;</span><br><span class="line">        String groupId = <span class="string">"order_wide_group"</span>;</span><br><span class="line"></span><br><span class="line">        FlinkKafkaConsumer&lt;String&gt; orderInfoKafkaSource = MyKafkaUtil.getKafkaSource(orderInfoSourceTopic, groupId);</span><br><span class="line">        FlinkKafkaConsumer&lt;String&gt; orderDetailKafkaSource = MyKafkaUtil.getKafkaSource(orderDetailSourceTopic, groupId);</span><br><span class="line">        DataStreamSource&lt;String&gt; orderInfoKafkaDS = env.addSource(orderInfoKafkaSource);</span><br><span class="line">        DataStreamSource&lt;String&gt; orderDetailKafkaDS = env.addSource(orderDetailKafkaSource);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3、将每行数据转换为JavaBean，提取时间戳生成WaterMark</span></span><br><span class="line">        WatermarkStrategy&lt;OrderInfo&gt; orderInfoWatermarkStrategy = WatermarkStrategy.&lt;OrderInfo&gt;forMonotonousTimestamps()</span><br><span class="line">                .withTimestampAssigner(<span class="keyword">new</span> SerializableTimestampAssigner&lt;OrderInfo&gt;() {</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(OrderInfo element, <span class="keyword">long</span> recordTimestamp)</span> </span>{</span><br><span class="line">                        <span class="keyword">return</span> element.getCreate_ts();</span><br><span class="line">                    }</span><br><span class="line">                });</span><br><span class="line"></span><br><span class="line">        WatermarkStrategy&lt;OrderDetail&gt; orderDetailWatermarkStrategy = WatermarkStrategy.&lt;OrderDetail&gt;forMonotonousTimestamps()</span><br><span class="line">                .withTimestampAssigner(<span class="keyword">new</span> SerializableTimestampAssigner&lt;OrderDetail&gt;() {</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(OrderDetail element, <span class="keyword">long</span> recordTimestamp)</span> </span>{</span><br><span class="line">                        <span class="keyword">return</span> element.getCreate_ts();</span><br><span class="line">                    }</span><br><span class="line">                });</span><br><span class="line"></span><br><span class="line">        KeyedStream&lt;OrderInfo, Long&gt; orderInfoWithIdKeyedStream = orderInfoKafkaDS.map(jsonStr -&gt; {</span><br><span class="line">            <span class="comment">// 时间格式化</span></span><br><span class="line">            SimpleDateFormat simpleDateFormat = <span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyy-MM-dd HH:mm:ss"</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 将JSON字符串转换为JavaBean</span></span><br><span class="line">            OrderInfo orderInfo = JSON.parseObject(jsonStr, OrderInfo.class);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 取出创建时间字段</span></span><br><span class="line">            String create_time = orderInfo.getCreate_time();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 按照空格分隔</span></span><br><span class="line">            String[] createTimeArr = create_time.split(<span class="string">" "</span>);</span><br><span class="line"></span><br><span class="line">            orderInfo.setCreate_date(createTimeArr[<span class="number">0</span>]);</span><br><span class="line">            orderInfo.setCreate_hour(createTimeArr[<span class="number">1</span>]);</span><br><span class="line">            orderInfo.setCreate_ts(simpleDateFormat.parse(create_time).getTime());</span><br><span class="line">            <span class="keyword">return</span> orderInfo;</span><br><span class="line">        }).assignTimestampsAndWatermarks(orderInfoWatermarkStrategy)</span><br><span class="line">                .keyBy(OrderInfo::getId);</span><br><span class="line"></span><br><span class="line">        KeyedStream&lt;OrderDetail, Long&gt; orderDetailWithOrderIdKeyedStream = orderDetailKafkaDS.map(jsonStr -&gt; {</span><br><span class="line">            SimpleDateFormat simpleDateFormat = <span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyy-MM-dd HH:mm:ss"</span>);</span><br><span class="line">            OrderDetail orderDetail = JSON.parseObject(jsonStr, OrderDetail.class);</span><br><span class="line">            orderDetail.setCreate_ts(simpleDateFormat.parse(orderDetail.getCreate_time()).getTime());</span><br><span class="line">            <span class="keyword">return</span> orderDetail;</span><br><span class="line">        }).assignTimestampsAndWatermarks(orderDetailWatermarkStrategy)</span><br><span class="line">                .keyBy(OrderDetail::getOrder_id);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4、双流JOIN</span></span><br><span class="line">        SingleOutputStreamOperator&lt;OrderWide&gt; orderWideDs = orderInfoWithIdKeyedStream.intervalJoin(orderDetailWithOrderIdKeyedStream)</span><br><span class="line">                .between(Time.seconds(-<span class="number">5</span>), Time.seconds(<span class="number">5</span>)) <span class="comment">// 生产环境，为了不丢失数据，设置时间为最大的延迟时间</span></span><br><span class="line">                .process(<span class="keyword">new</span> ProcessJoinFunction&lt;OrderInfo, OrderDetail, OrderWide&gt;() {</span><br><span class="line"></span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(OrderInfo left, OrderDetail right, Context ctx, Collector&lt;OrderWide&gt; out)</span> <span class="keyword">throws</span> Exception </span>{</span><br><span class="line">                        out.collect(<span class="keyword">new</span> OrderWide(left, right));</span><br><span class="line">                    }</span><br><span class="line">                });</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 测试打印</span></span><br><span class="line">        orderWideDs.print();</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 执行任务</span></span><br><span class="line">        env.execute(<span class="string">"OrderWideApp &gt;&gt;&gt; "</span>);</span><br><span class="line"></span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>

<p><em><strong>学习链接</strong></em></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u013516966/article/details/102952239">https://blog.csdn.net/u013516966/article/details/102952239</a></p>
<p>整个处理逻辑都是基于数据时间的，也就是intervaljoin 必须基于EventTime语义，在between 中有做TimeCharacteristic是否为EventTime校验, 如果不是则抛出异常。</p>
<h4 id="5-2-维度关联"><a href="#5-2-维度关联" class="headerlink" title="5.2 维度关联"></a>5.2 维度关联</h4><p>这个就是维度得封装</p>
<h4 id="5-3-优化1：加入旁路缓存模式"><a href="#5-3-优化1：加入旁路缓存模式" class="headerlink" title="5.3 优化1：加入旁路缓存模式"></a>5.3 优化1：加入旁路缓存模式</h4><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">直接查询，出现流式计算得性能瓶颈，cache</span> <span class="string">aside pattern</span></span><br><span class="line"><span class="attr">中间加了一个缓存层</span></span><br><span class="line"><span class="attr">hbase关闭得时候要执行一次刷写操作</span></span><br><span class="line"></span><br><span class="line"><span class="attr">维度数据</span></span><br><span class="line"><span class="meta">订单宽表</span> <span class="string">---&gt; 缓存（Redis）---&gt; 维度数据</span></span><br><span class="line"><span class="attr">未命中，在查Phoenix，查到了要同步Redis，查到得数据同步到Redis</span></span><br><span class="line"></span><br><span class="line"><span class="attr">1、缓存要设置过期时间，不然数据常驻内存浪费资源，要考虑维度数据是否发生变化，如果发生变化要主动清除缓存</span></span><br><span class="line">	<span class="attr">如何清除缓存，维度数据可能发生变化，</span></span><br><span class="line"><span class="attr">2、使用Redis来缓存</span></span><br><span class="line">	<span class="attr">公司当中采用二级缓存，堆内存，查询数据，在hashMap钟，以后查询数据都在Map中查找一下，</span></span><br><span class="line"><span class="meta">二级缓存，Phoenix</span> <span class="string">Redis MemCache 堆内存当前程序得内存</span></span><br><span class="line">	<span class="meta">堆内存采用得是HashMap，Phoenix</span> <span class="string">---&gt; Redis ---&gt; 堆内存</span></span><br><span class="line">	<span class="attr">代码DBbaseLog，进程得堆内存</span></span><br><span class="line">	<span class="attr">Redis是一个独立得服务，公用得资源，HashMap是一个linkedHashMap</span></span><br><span class="line">	<span class="meta">加入了一个LRU</span> <span class="string">CAche</span></span><br><span class="line">	<span class="attr">jdbc</span> <span class="string">也有，最近最少使用得算法</span></span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.mysql.cj.util;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.LinkedHashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map.Entry;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LRUCache</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">LinkedHashMap</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>{</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">1L</span>;</span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">int</span> maxElements;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LRUCache</span><span class="params">(<span class="keyword">int</span> maxSize)</span> </span>{</span><br><span class="line">        <span class="keyword">super</span>(maxSize, <span class="number">0.75F</span>, <span class="keyword">true</span>);</span><br><span class="line">        <span class="keyword">this</span>.maxElements = maxSize;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">boolean</span> <span class="title">removeEldestEntry</span><span class="params">(Entry&lt;K, V&gt; eldest)</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.size() &gt; <span class="keyword">this</span>.maxElements;</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">查询前</span> <span class="string">---&gt; Redis ---&gt; 查询之后同步到Redis中</span></span><br><span class="line"><span class="attr">测试数据；</span></span><br><span class="line"><span class="meta">Redis重要的一点就是布隆过滤器</span> <span class="string">flushall ---&gt; 这个是测试</span></span><br><span class="line"><span class="attr">加速测试，查询添加删除，这种过程的话增加我们的性能</span></span><br><span class="line"></span><br><span class="line"><span class="attr">创建连接慢，并不是访问慢，加一个缓存就是为了减少和phoenix之间的交互</span></span><br><span class="line"></span><br><span class="line"><span class="attr">问题：</span></span><br><span class="line"><span class="attr">如果数据更新了，在DimUtil增加失效缓存的方法，维度数据变化时要失效的缓存</span></span><br><span class="line"><span class="attr">Redis中删除一个内容的时候，是不需要取判断它是否存在的，不会报错，只会返回0或者1</span></span><br><span class="line"></span><br><span class="line"><span class="attr">在DWD入库的时候，我们增加了缓存的操作，这样的话，可以增加性能，所以我们需要测试各种情况说明</span></span><br><span class="line"></span><br><span class="line"><span class="attr">内存数据库，毕竟是一个外部系统，所以尽量的要去避免q</span></span><br></pre></td></tr></tbody></table></figure>

<h4 id="5-4-优化2：异步查询"><a href="#5-4-优化2：异步查询" class="headerlink" title="5.4 优化2：异步查询"></a>5.4 优化2：异步查询</h4><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">在Flink流处理中，经常需要和外部系统来进行交互，用维度表不全事实表中的字段，例如：在电商场景中，需要一个商品的skuid去关联商品的一些属性，例如商品所属行业商品的生产厂家，生产厂家的一些情况，在物流场景中，知道包裹ID，需要去关联包裹行业属性，发货信息，收货信息等</span></span><br><span class="line"></span><br><span class="line"><span class="attr">默认情况下，在Flink的MapFunction中，单个并行度只能用同步的方式去交互，将请求发送到外部系统中，IO阻塞，等待请求返回，然后继续发送下一个请求，这种同步交互的方式往往在网络等待上就耗费了大量时间，为了提高处理效率，可以增加MapFunction的并行度，当增加并行度就意味着更多的资源，并不是一种非常好的解决方式</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Async</span> <span class="string">I/O 是阿里巴巴贡献给社区的一个呼声非常高的一个特性，解决与外部系统交互时网络延迟成为了系统瓶颈的问题</span></span><br><span class="line"></span><br><span class="line"><span class="attr">异步查询实际上是把维表的查询操作托管给单独的线程池完成，这样不会以为某一个查询造成阻塞，单个并行可以连续发送给多个请求，提供并发效率</span></span><br><span class="line"></span><br><span class="line"><span class="attr">排序或者不排序的，对这个数据的顺序是没有什么影响的，所以我们没有排序</span></span><br></pre></td></tr></tbody></table></figure>

<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210722075324509.png" alt="查看异步操作"></p>
<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210722075401510.png" alt="异步IO"></p>
<p><a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/zh/docs/dev/datastream/operators/asyncio/">Flink I/O 异步</a></p>
<figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">MapFunction是一个同步的请求，MapFunction，知道回应被收到之后在进行处理，这个是同步的，等待请求的方式不好，并行的话，去消耗资源，线程连接，数据库的连接，缓冲和内存也增加了，资源的占用也就更高了</span> <span class="string"></span></span><br><span class="line"><span class="attr">异步IO和提高并行度是优化的两种方式</span></span><br><span class="line"><span class="attr">增加机器也是一种优化方案，最有效的方案</span></span><br><span class="line"></span><br><span class="line"><span class="attr">条件：</span></span><br><span class="line"><span class="attr">１、数据库需要支持异步交互操作客户端</span></span><br><span class="line"><span class="attr">２、如果没有这种客户端，可以创建多个客户端，使用多线程的方式来调用这种方案，比正规的异步方案要低很多　－－－＞　多线池和多线程</span></span><br><span class="line"></span><br><span class="line"><span class="attr">启动一个线程所需要的方式</span></span><br><span class="line"><span class="meta">Runnable,new</span> <span class="string">Thread ---&gt; 都不建议去使用</span></span><br><span class="line"><span class="attr">去创建一个线程池来进行使用</span></span><br><span class="line"></span><br><span class="line"><span class="meta">实现分发请求的</span> <span class="string">AsyncFunction  ---&gt; 自定义的</span></span><br><span class="line"><span class="meta">获取数据库交互的结果并发送给</span> <span class="string">ResultFuture 的 回调 函数，继续返回到流中，维度信息关联之后才能往下游去传递，结果响应好了之后然后才回调</span></span><br><span class="line"><span class="meta">将异步</span> <span class="string">I/O 操作应用于 DataStream 作为 DataStream 的一次转换操作。</span></span><br><span class="line"></span><br><span class="line"><span class="meta">是否进行排序的操作，unOrder效率更高，不用</span> <span class="string">管进来的顺序，如果数据又顺序要求还是使用order</span></span><br><span class="line"></span><br><span class="line"><span class="attr">TimeOut，超时时间，只有拿到响应才能把数据往下传递，交给超时的数据去传送就好了</span></span><br><span class="line"><span class="meta">Capacity：</span> <span class="string">容量参数定义了可以同时进行的异步请求数。 即使异步 I/O 通常带来更高的吞吐量，执行异步 I/O 操作的算子仍然可能成为流处理的瓶颈。 限制并发请求的数量可以确保算子不会持续累积待处理的请求进而造成积压，而是在容量耗尽时触发反压</span></span><br><span class="line"></span><br><span class="line"><span class="attr">超时的话可以去选择性的去重写它</span></span><br><span class="line"></span><br><span class="line"><span class="attr">DimAsyncFunction</span></span><br><span class="line"></span><br><span class="line"><span class="attr">关联之后也还是都一样的，如果把类型写死了，这样不太好，我们可以使用泛型来进行限制</span></span><br><span class="line"></span><br><span class="line"><span class="attr">open</span> <span class="string">asyncInvoke timeout</span></span><br><span class="line"><span class="meta">1、初始化线程池</span> <span class="string">---&gt; 线程池的工具类 JUC中，提供了ThreadPoolExecutor pool</span></span><br><span class="line"><span class="attr">使用懒汉式和饿汉式</span></span><br><span class="line"></span><br><span class="line"><span class="attr">LinkedBlockingQueue</span>  <span class="string">---&gt; 有界</span></span><br><span class="line"><span class="attr">ArrayBlockingQueue</span>   <span class="string">---&gt; 无界</span></span><br><span class="line"></span><br><span class="line"><span class="attr">TheadPoolUtil</span> <span class="string">---&gt; 连接池</span></span><br><span class="line"><span class="attr">不能确保一个并行度一个连接池</span></span><br><span class="line"><span class="meta">单例模式</span> <span class="string">---&gt; 饿汉式，加锁机制，双重判断模式，锁的是new 操作</span></span><br><span class="line"><span class="attr">两个人同时判断，此时都是null，A先拿到，B在外面，如果加了锁之后，A创建之后就不创建了</span></span><br><span class="line"></span><br><span class="line"><span class="attr">编写代码的技巧：</span></span><br><span class="line">    <span class="attr">1、如果有些方法我们是不确定的，我们可以使用抽象类加抽象方法的思路来进行维度的关联，既然确定不了，那么就提取到外部进行编写代码</span></span><br><span class="line">    <span class="attr">2、刚开始编写代码的时候，我们是采用在DimAsyncFunction中定义一个抽象，最后我们是把规范接口给设置下来了</span></span><br><span class="line">    <span class="attr">3、方法模板，很多封装的方法，我们可以封装成一个模板，这样在封装的时候就不会报错了，如果在封装当中是实现不了的，使用的时候在进行一个重写的操作</span></span><br></pre></td></tr></tbody></table></figure>

<p><em><strong>测试</strong></em></p>
<figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">测试异步查询的操作</span></span><br><span class="line"><span class="attr">测试用户维度关联</span></span><br><span class="line">	<span class="attr">1、将table_process表中的数据删除掉，需要往这个表中添加维度和事实的一些基本的配置信息</span></span><br><span class="line">	<span class="attr">2、启动程序：</span></span><br><span class="line">		<span class="meta">CDC（mysql</span> <span class="string">---&gt; kafka）</span></span><br><span class="line">		<span class="attr">zk</span></span><br><span class="line">		<span class="attr">kafka</span></span><br><span class="line">		<span class="attr">hdfs</span></span><br><span class="line">		<span class="attr">hbase</span></span><br><span class="line">		<span class="attr">redis</span></span><br><span class="line">	<span class="attr">3、运行APP</span></span><br><span class="line">		<span class="attr">DbBaseApp</span> <span class="string">---&gt; 这个分析的是一个业务数据</span></span><br><span class="line">	<span class="meta">4、初始化用户维度数据到hbase中（可以使用FLink</span> <span class="string">CDC的方式）</span></span><br><span class="line">	<span class="meta">5、运行OrderWideApp</span> <span class="string">---&gt; 订单信息和订单明细来join成的一个订单宽表</span></span><br><span class="line">	<span class="attr">6、打包测试</span></span><br><span class="line">	<span class="attr">7、查看kafka中是否又年龄和性别这个两个数据的信息</span></span><br></pre></td></tr></tbody></table></figure>

<p><em><strong>测试心得</strong></em></p>
<figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">DbBaseApp</span> <span class="string">---&gt; 用户的维度信息已经到Phoenix中的</span></span><br><span class="line"><span class="attr">OrderWideApp</span> <span class="string">---&gt; 关联维度 (Redis)</span></span><br><span class="line"></span><br><span class="line"><span class="attr">重点：</span></span><br><span class="line">    <span class="meta">1、从MySQL中存储的是一个业务数据，所以我们需要把这些维度数据存储在hbase中，所以我们加入了Redis的旁路缓存的方式来进行优化hbaseJsonDS.addSink(new</span> <span class="string">DimSink()) 查询到的数据就写到redis中，如果是update操作的化就直接删除，还要设置一些过期的时间操作</span></span><br><span class="line"></span><br><span class="line"><span class="attr">从hbase中读取维度和kafka中的数据进行关联</span></span><br><span class="line"></span><br><span class="line"><span class="attr">这些都关联好了之后，然后进行一个最后的一个测试</span></span><br><span class="line"></span><br><span class="line"><span class="meta">只不过重要的一点就是如何同步MySQL中的业务数据到kafka中，可以通过CDC</span> <span class="string">来进行一个完成操作</span></span><br><span class="line"></span><br><span class="line"><span class="attr">后续的都基本上都是一致的</span></span><br><span class="line"></span><br><span class="line"><span class="attr">是整个项目的难度和重点</span></span><br><span class="line"><span class="meta">动态分流</span> <span class="string">---&gt; 日志数据</span></span><br><span class="line"><span class="meta">业务数据</span> <span class="string">---&gt; Redis旁路缓存、异步查询、线程池</span></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

<h3 id="６、支付宽表"><a href="#６、支付宽表" class="headerlink" title="６、支付宽表"></a>６、支付宽表</h3><h4 id="6-1-需求分析与思路"><a href="#6-1-需求分析与思路" class="headerlink" title="6.1 需求分析与思路"></a>6.1 需求分析与思路</h4><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">支付宽表的目的，最主要的原因时支付表没有到订单明细，支付金额没有细分到商品上，没有办法统计商品级的支付状况。</span></span><br><span class="line"><span class="attr">所以本次宽表的核心就是要把支付表的信息与订单明细关联上</span></span><br><span class="line"></span><br><span class="line"><span class="attr">解决方案有两个</span></span><br><span class="line"><span class="attr">1、一个是把订单明细（宽表）输出到hbase上，在支付宽表计算查询hbase，这相当于把订单明细作为一种维度进行管理</span></span><br><span class="line"><span class="meta">2、一个是把用流的方式接受订单明细，然后用双流join方式进行合并，因为订单与支付产生有一定时差，所以必须使用Interval</span> <span class="string">join来管理流的状态时间</span></span><br><span class="line"></span><br><span class="line"><span class="attr">BeanUtils.copyProperties</span></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure>

<p><em><strong>测试数据</strong></em></p>
<figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kafka、zk、hbase、hdfs、phoenix、redis</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---&gt;</span> <span class="string">业务数据</span></span><br><span class="line"><span class="attr">ods_base_db_m</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---&gt;</span> <span class="string">动态分流</span></span><br><span class="line"> <span class="meta">---&gt;</span> <span class="string">Redis 旁路缓存</span></span><br><span class="line"> <span class="meta">---&gt;</span> <span class="string">线程池、Flink异步查询</span></span><br><span class="line"><span class="attr">dwd_order_info</span></span><br><span class="line"><span class="attr">dwd_order_detail</span></span><br><span class="line"><span class="attr">dwd_payment_info</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---&gt;</span> <span class="string">双流join</span></span><br><span class="line"><span class="attr">dwm_order_wide</span></span><br><span class="line"><span class="attr">dwm_payment_wide</span></span><br><span class="line"></span><br><span class="line"><span class="meta">生成数据</span> <span class="string">---&gt;  DWM</span></span><br></pre></td></tr></tbody></table></figure>

<h4 id="6-2-支付宽表和时间工具类"><a href="#6-2-支付宽表和时间工具类" class="headerlink" title="6.2 支付宽表和时间工具类"></a>6.2 支付宽表和时间工具类</h4><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">SimpleDateFormat：线程安全问题</span></span><br><span class="line"><span class="attr">来一条创建一条，多线程操作过程中同时操作一个对象，如果只是读没有影响</span></span><br><span class="line"><span class="attr">sdf</span> <span class="string">---&gt; calendar ---&gt; setTime</span></span><br><span class="line"></span><br><span class="line"><span class="attr">StringBuffer</span></span><br><span class="line"></span><br><span class="line"><span class="attr">DateTimeUtil</span> <span class="string">---&gt; 编写一个时间工具类</span></span><br><span class="line"></span><br><span class="line"><span class="attr">map和提取时间戳，都是单线程的，多个并行度也不会有同一个，如果提出去，也是没有问题，都是单线程在执行，submit都是单线程在进行执行的</span></span><br></pre></td></tr></tbody></table></figure>

<h2 id="DWM-回顾"><a href="#DWM-回顾" class="headerlink" title="DWM 回顾"></a>DWM 回顾</h2><h3 id="0、实时数仓架构"><a href="#0、实时数仓架构" class="headerlink" title="0、实时数仓架构"></a>0、实时数仓架构</h3><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">Springboot用来写数据接口层的，所以有时间我还是要学习一下</span></span><br><span class="line"><span class="attr">维度表和事实表</span></span><br><span class="line"><span class="attr">DWS</span></span><br></pre></td></tr></tbody></table></figure>

<h3 id="1、行为数据-数据流"><a href="#1、行为数据-数据流" class="headerlink" title="1、行为数据 数据流"></a>1、行为数据 数据流</h3><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">动态分流</span></span><br><span class="line"><span class="attr">旁路缓存</span></span><br><span class="line"><span class="attr">异步查询</span></span><br></pre></td></tr></tbody></table></figure>

<h3 id="2、业务数据、动态分流"><a href="#2、业务数据、动态分流" class="headerlink" title="2、业务数据、动态分流"></a>2、业务数据、动态分流</h3><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">Canal/MaxWell</span></span><br><span class="line"><span class="attr">Flink</span> <span class="string">CDC</span></span><br><span class="line"></span><br><span class="line"><span class="attr">读取数据，分流split</span></span><br><span class="line"><span class="attr">使用侧输出流，processFunction的方式</span></span><br><span class="line"></span><br><span class="line"><span class="attr">先读取一次配置信息，然后周期性的读取配置信息，Phoenix配置</span></span><br><span class="line"><span class="attr">先加载一次配置信息，因为周期性的任务开始，读取数据，开启另外一个线程，一直在调度，一旦我们开启任务调度open方法已经完成，周期性的任务市没有办法完成的</span></span><br><span class="line"></span><br><span class="line"><span class="attr">mysql</span> <span class="string">map 建表</span></span><br><span class="line"><span class="attr">processFunction</span></span><br><span class="line"></span><br><span class="line"><span class="attr">记住，我们在同步数据的时候一定要注意，变更数据的那个字段是否和我们配置表中的字段是否是一样的</span></span><br><span class="line"><span class="attr">自己说的多就犯错越少</span></span><br><span class="line"><span class="meta">使用maxwell</span> <span class="string">的 operator_insert 和我们的insert做了一个处理，注意是要了解JSON的格式</span></span><br><span class="line"><span class="attr">我们加了字段Sink_table，主题都是在配置信息中，配置信息把sink_table，接下来我们才真正做了过滤字段，可以不用过滤，生产环境当中建议都是要保留的，因为多了比少了好</span></span><br><span class="line"></span><br><span class="line"><span class="attr">如果少了的话，业务线都得改，早期设计的话，前面的话都要，业务线很清洗之后然后才能对字段有一个明确的认识</span></span><br><span class="line"></span><br><span class="line"><span class="attr">驼峰命名，泛型，这个面试的话，就不需要去聊了</span></span><br></pre></td></tr></tbody></table></figure>

<h3 id="3、业务数据-异步IO"><a href="#3、业务数据-异步IO" class="headerlink" title="3、业务数据 异步IO"></a>3、业务数据 异步IO</h3><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">动态分流这个图的话，可以去好好的整理一下</span></span><br><span class="line"><span class="attr">记住在建表的时候，一定要注意单引号的一个问题，要不然的话就会报错</span></span><br><span class="line"><span class="attr">id,t_name</span></span><br><span class="line"><span class="attr">id</span>:<span class="string">varchar,t_name:varchar</span></span><br><span class="line"><span class="meta">这个往哪里放数据勒，这个就是太麻烦了，一个字段的字段的判断，upsert</span> <span class="string">的SQL复杂程度写出去没有关系，用得时候在转一下就好了，正常的往里面写就行</span></span><br><span class="line"></span><br><span class="line"><span class="attr">封装一个工具类，写到Kafka，主题的数据，都是在一个流中，没有办法写死这个主题，我们选择了自定义Shema，把主题信息给携带者，ProducerRecord</span></span><br><span class="line"></span><br><span class="line"><span class="attr">订单宽表</span></span><br><span class="line"><span class="meta">两张事实表</span>  <span class="string">---&gt; order_info order_detail 双流join</span></span><br><span class="line"><span class="meta">六张维度表</span>  <span class="string">---&gt; 用户、省份、sku、spu、品牌、品类</span></span><br><span class="line"><span class="attr">需要考虑先关联那个维度</span></span><br><span class="line"><span class="attr">注意顺序：</span></span><br><span class="line"><span class="attr">sku</span> <span class="string">---&gt; spu、品牌、品类</span></span><br><span class="line"><span class="attr">只有是在后面就行</span></span><br><span class="line"></span><br><span class="line"><span class="attr">默认是保存的是几天，他是没有办法去考量的</span></span><br><span class="line"><span class="attr">AsyncFunction</span></span><br><span class="line"><span class="attr">getKey()</span></span><br><span class="line"><span class="attr">join()封装的是也给泛型的方法</span></span><br><span class="line"></span><br><span class="line"><span class="attr">支付事实表</span></span><br><span class="line"><span class="attr">和订单宽表的宽连都是类似的</span></span><br></pre></td></tr></tbody></table></figure>

<h2 id="DWS-与-DWM-层的设计"><a href="#DWS-与-DWM-层的设计" class="headerlink" title="DWS 与 DWM 层的设计"></a>DWS 与 DWM 层的设计</h2><h3 id="1、设计思路"><a href="#1、设计思路" class="headerlink" title="1、设计思路"></a>1、设计思路</h3><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">我们在之前通过分流等手段，把数据分拆成了独立的kafka</span> <span class="string">topic，那么接下来如何处理数据，就要思考一下我们到底要通过实时计算出那些指标项</span></span><br><span class="line"><span class="attr">因为实时计算和离线不同，实时计算的开发和运维成本都是非常高的，要结合实际情况考虑是否有必要像离线数仓一样，建一个大而全的中间层</span></span><br><span class="line"><span class="attr">如果没有必要大而全，这个时候就需要大体规划一下要实时计算出的指标的需求，把这些指标以宽表的形式输出就是我们的DWS层</span></span><br><span class="line"></span><br><span class="line"><span class="attr">beeline</span> <span class="string">-u jdbc:hive2://hadoop102:10000 -n wmy</span></span><br><span class="line"><span class="attr">hive</span> <span class="string">--service hiveserver2 ----&gt; hiveserver.sh</span></span><br><span class="line"></span><br><span class="line">================== <span class="attr">访客主题宽表的计算</span></span><br><span class="line"><span class="meta">统计主题</span>	<span class="string">需求指标		输出方式		计算来源				来源层级</span></span><br><span class="line"><span class="meta">访客</span>		  <span class="string">PV	    	可视化大屏		page_log直接求			 dwd</span></span><br><span class="line"><span class="meta">访客</span>		  <span class="string">UV			可视化大屏		page_log过滤去重		dwm</span></span><br><span class="line"><span class="meta">访客</span>		  <span class="string">跳出率     	  可视化大屏	 	  page_log行为判断		  dwm</span></span><br><span class="line"><span class="meta">访客</span>		  <span class="string">进入页面数		 可视化大屏	 	 需要访问开始标记		  dwd</span></span><br><span class="line"><span class="meta">访客</span>		  <span class="string">连续访问时长    可视化大屏		 page_log直接求		 dwd</span></span><br><span class="line"></span><br><span class="line"><span class="attr">设计一张表DWS层的表其实就是两件事，维度和度量（事实数据）</span></span><br><span class="line">	<span class="attr">1、度量包括PV、UV、跳出次数、进入页面数（session_count）、连续访问时长</span></span><br><span class="line">	<span class="attr">2、维度包括在分析中的比较重要的几个字段，渠道、地区、版本、新老用户进行聚合</span></span><br><span class="line"></span><br><span class="line"><span class="attr">coaleasce</span> <span class="string">三张表join的时候，dwm，dws</span></span><br><span class="line"><span class="meta">flink,union</span> <span class="string">,connect,我们在聚合的时候采用的是union的操作，不用考虑是否存在的情况</span></span><br><span class="line"></span><br><span class="line"><span class="attr">select</span> <span class="string">* from tableA full join tableB on tableA.id = tableB.id full join tableC on coaleasce(tableA.id,tableB.id)=tableC.id;</span></span><br></pre></td></tr></tbody></table></figure>

<h3 id="2、实现过程"><a href="#2、实现过程" class="headerlink" title="2、实现过程"></a>2、实现过程</h3><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">三个主题，四个流，五个指标</span></span><br><span class="line"><span class="attr">String</span> <span class="string">pageViewSourceTopic = "dwd_page_log"; // LogBaseApp</span></span><br><span class="line"><span class="attr">String</span> <span class="string">uniqueVisitSourceTopic = "dwm_unique_visit"; //DayAcitilyUserCountApp</span></span><br><span class="line"><span class="attr">String</span> <span class="string">userJumpDetailSourceTopic = "dwm_user_jum_detail";//UserJumpDetailApp</span></span><br><span class="line"></span><br><span class="line"><span class="meta">3.1</span> <span class="string">将页面流格式化为VisitorStats ---&gt; PV和访问时长</span></span><br><span class="line"><span class="meta">3.2</span> <span class="string">将页面数据流像过滤格式化为VisitorStats ---&gt; sv_ct（进入次数）</span></span><br><span class="line"><span class="meta">3.3</span> <span class="string">将uvDS格式化为VisitorStats ---&gt; UV</span></span><br><span class="line"><span class="meta">3.4</span> <span class="string">将userJumpDS格式化为VisitorStats ---&gt; uj_ct(跳出次数)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">//度量：独立访客数</span> <span class="string">uv_ct</span></span><br><span class="line"><span class="meta">//度量：页面访问数</span> <span class="string">pv_ct</span></span><br><span class="line"><span class="meta">//度量：</span> <span class="string">进入次数 sv_ct</span></span><br><span class="line"><span class="meta">//度量：</span> <span class="string">跳出次数 uj_ct</span></span><br><span class="line"><span class="meta">//度量：</span> <span class="string">持续访问时间 dur_sum</span></span><br></pre></td></tr></tbody></table></figure>

<p><em><strong>union</strong></em></p>
<figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">union</span> <span class="string">类型必须是一样的</span></span><br><span class="line"><span class="meta">使用flink</span> <span class="string">sql 也能做，flink sql 也有full join</span></span><br></pre></td></tr></tbody></table></figure>

<h2 id="DWS-访客主题"><a href="#DWS-访客主题" class="headerlink" title="DWS 访客主题"></a>DWS 访客主题</h2><p> 开窗处理 思路分析</p>
<figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">重点：将时间格式化转换为最新版本的，要不然会出现线程等安全的问题</span></span><br><span class="line"></span><br><span class="line"><span class="meta">测试：resultDS.print("resultDS</span> <span class="string">&gt;&gt;&gt;&gt; ");</span></span><br><span class="line"><span class="meta">最后的指标就是从Clickhouse</span> <span class="string">写SQL出来</span></span><br><span class="line"></span><br><span class="line"><span class="meta">kafka中有多少个主题</span>   <span class="string">--- &gt; 事实表</span></span><br><span class="line"><span class="attr">dwd_cart_info</span></span><br><span class="line"><span class="attr">dwd_category1</span></span><br><span class="line"><span class="attr">dwd_comment_info</span></span><br><span class="line"><span class="attr">dwd_display_log</span></span><br><span class="line"><span class="attr">dwd_order_detail</span></span><br><span class="line"><span class="attr">dwd_order_info</span></span><br><span class="line"><span class="attr">dwd_order_refund_info</span></span><br><span class="line"><span class="attr">dwd_page_log</span></span><br><span class="line"><span class="attr">dwd_payment_info</span></span><br><span class="line"><span class="attr">dwd_refund_payment</span></span><br><span class="line"><span class="attr">dwd_start_log</span></span><br><span class="line"><span class="attr">dwm_order_wide</span></span><br><span class="line"><span class="attr">dwm_payment_wide</span></span><br><span class="line"><span class="attr">dwm_unique_visit</span></span><br><span class="line"><span class="attr">dwm_user_jump_detail</span></span><br><span class="line"><span class="attr">ods_base_db</span></span><br><span class="line"><span class="attr">ods_base_log</span></span><br><span class="line"></span><br><span class="line"><span class="attr">生产日志数据流</span></span><br><span class="line"><span class="attr">每隔十秒钟会出一次key</span></span><br><span class="line"></span><br><span class="line"><span class="attr">如果不是10秒钟的，会出现很多次，如果没有汇总的情况的话，性能会很低调的，所以最好是做一个开窗的处理</span></span><br><span class="line"></span><br><span class="line"><span class="attr">也可以使用测试一下不开窗的统计，reduce，这个打印的数据的话，一直在打印这个流一直在刷，如果是真的这样的话,clickhouse的性能不好，还得要求clickhouse那边有去重的功能</span></span><br></pre></td></tr></tbody></table></figure>

<h3 id="4、DWS层回顾"><a href="#4、DWS层回顾" class="headerlink" title="4、DWS层回顾"></a>4、DWS层回顾</h3><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">数据流的回复</span></span><br><span class="line"><span class="attr">画图，每天画一次</span></span><br><span class="line"><span class="attr">DWS层，根据需求来，维度指标都合并在大宽表中，由公司定，自己知道从那些维度表中出来</span></span><br><span class="line"><span class="attr">学会归类，除了现在的需求，能不能多考虑一下扩展，以后能不能用，对于商品来说，点击、曝光、收藏、那些商品就可以放到一个大宽表</span></span><br><span class="line"><span class="attr">商品、地区、关键词都是一些重点</span></span><br><span class="line"><span class="attr">来源去哪里取数据，需求DWS一定是根据需求有关的，聊数仓的维度建模，说离线和实时，都一定要分清，ods,dwd，跟业务比较低</span></span><br><span class="line"><span class="meta">dwm,dws</span> <span class="string">---&gt; dws是每天，lambda，不是分开的，实时去拿结果，如果过了今天，这个时候可以去走离线的数仓，走的是离线的结果</span></span><br><span class="line"><span class="meta">dws,dwt</span> <span class="string">---&gt; 每天的聚合，dwt是一个累积的结果</span></span><br><span class="line"></span><br><span class="line"><span class="attr">实时的数据流侧重于一个时效性，牺牲准确性保证时效性，水位线和延迟，侧输出流，以最快的时间看近似的结果，然后在慢慢的走，两个数仓不是分开的，本质的性能都是一样，分析指标都是类似的</span></span><br><span class="line"><span class="attr">离线和实时的指标都是一样的</span></span><br><span class="line"></span><br><span class="line"><span class="meta">离线</span> <span class="string">flume</span></span><br><span class="line"><span class="meta">实时Spring</span> <span class="string">boot 直接将数据写到kafka</span></span><br><span class="line"><span class="meta">这些都是可以做离线和实时，实时是用spring</span> <span class="string">boot，两套不可能同时去跑，主题的数据是否重复，如果不用的话，不就是一个浪费的，这个是不合理的</span></span><br><span class="line"></span><br><span class="line"><span class="attr">聊架构，只有一套架构，先开始离线部分，flume采集的这种，但是一般来说，公司很少有做架构，太复杂的，实在不行了才更新，越大的更新，公司用得都比较低公司不会轻易的去换的</span></span><br><span class="line"></span><br><span class="line"><span class="attr">公司运行了很多项目，过期的代码和实例都是白写了，架构也是一样，统一说一套就好了，实时性的要求比较高，两套架构的优缺点都有优点和缺点，更看重的是缺点</span></span><br><span class="line"></span><br><span class="line"><span class="attr">面试的时候，不能是完美无缺的，存在即合理的情况</span></span><br><span class="line"></span><br><span class="line"><span class="attr">主题：dws：访客主题宽表的计算</span></span><br><span class="line"><span class="attr">pv</span></span><br><span class="line"><span class="attr">uv</span></span><br><span class="line"><span class="meta">跳出率</span> <span class="string">---&gt; 行为判断，先求出跳出数</span></span><br><span class="line"><span class="meta">进入页面数</span> <span class="string">---&gt; 开始访问表示，last_page_id为null</span></span><br><span class="line"><span class="meta">连续访问时长</span> <span class="string">---&gt; 这个做一个累加的就好了，三个主题四个流五个指标</span></span><br><span class="line"><span class="attr">可以来自于同一个流一次性算出来的，最早是来自同一个主题，直接可以page_log来进行求出</span></span><br><span class="line"></span><br><span class="line"><span class="attr">CEP提取的是一个超时的数据，要的是后面不存在的数据，定一个10秒的匹配时间，如果匹配不上，超时那么就认为是没有吓一跳数据，这个是有相似点的，有包含关系的，前一跳和后一跳</span></span><br><span class="line"></span><br><span class="line"><span class="meta">数据的加工方式不同而已，直接从dwm</span> <span class="string">---&gt; UV、跳出率</span></span><br><span class="line"></span><br><span class="line"><span class="attr">除了算指标以外，还要加入各种维度信息，如果不加入维度的话，对于后期的分析很难</span></span><br><span class="line"><span class="attr">渠道、地区、版本、新老用户</span></span><br><span class="line"><span class="attr">对总的进行sum，分组求和的操作，最细粒度的指标进行更高维的指标是没有问题的</span></span><br><span class="line"><span class="attr">有维度的基础上去掉维度是很简单的</span></span><br><span class="line"></span><br><span class="line"><span class="attr">来自于四个流的数据，合并join或者是union，join，包含了connect，可以作为join,比join更加的另外，除了常用的（左右全外）join之后还有</span></span><br><span class="line"></span><br><span class="line"><span class="attr">connect算子，首先和join,connect除了那些，之前写代码做过全外</span></span><br><span class="line"><span class="attr">实时对账可以做全外连接</span></span><br><span class="line"><span class="attr">两条流保存状态，没有数据保存在状态中，如果只是写左边的数据，两边都写的</span></span><br><span class="line"><span class="attr">dataStream一定要想到connect</span></span><br><span class="line"><span class="attr">window</span> <span class="string">join在窗口的内部，不能跨窗口进行join</span></span><br><span class="line"><span class="attr">只有connect</span></span><br><span class="line"></span><br><span class="line"><span class="meta">如果是flink</span> <span class="string">sql，full join，inner join left join ,right join</span></span><br><span class="line"><span class="attr">connect</span> <span class="string">在API中比join还强大的，保存状态之外，还强大了,inner join必须是keyedStream</span></span><br><span class="line"><span class="attr">connect是不要求keyedStream，更加的灵活</span></span><br><span class="line"><span class="attr">包含关系keyedStream表示的范围更加的小</span></span><br><span class="line"><span class="attr">inner</span> <span class="string">jion要求更多一些,on</span></span><br><span class="line"></span><br><span class="line"><span class="attr">connect只是简单的将两个流合并成一个流，想到join或者是Union，不能保证这些都有这些的维度的组合，怎么可能那些维度和key相同</span></span><br><span class="line"><span class="meta">会想到用full</span> <span class="string">join,如果想到用connect的话，这样真的好麻烦，hive sql中使用coalsce这样的话要好一些，转换为javabean</span></span><br><span class="line"></span><br><span class="line"><span class="meta">可以转换一个表对象来进行full</span> <span class="string">join，关联的字段使用coalsce防止出现一个膨胀的情况，如果真的注意一下这个全外连接的一个坑，union的方法，既有flink sql和flink datastream</span></span><br><span class="line"><span class="attr">在公司当中使用一个就好了，公司当中很少有两套的，其它人接你的项目也会很通过，中间还调了一下python脚本，尽量的话统一，学东西，都尽量的去学一些</span></span><br><span class="line"></span><br><span class="line"><span class="attr">用的话随便拿来用一下就好了，随便用一下就好了</span></span><br><span class="line"><span class="attr">在数仓中的用法都是一样的，可视化数据，都必须是一样的额，在代码中传的类型必须是完全一样的</span></span><br><span class="line"></span><br><span class="line"><span class="meta">union，补零的操作，如果不写的这样</span> <span class="string">可以吗，第一张表，补的字段都是必须给写上的，构造方法就会报错了</span></span><br><span class="line"></span><br><span class="line"><span class="attr">开窗和水位线是否能去重，或者clickhouse是否能够接受这个性能的访问，这个数据的访问，一组数据，四个维度组合的组合数据，在这个10秒钟，本来是有很多条的话，正常往里面写</span></span><br><span class="line"></span><br><span class="line"><span class="attr">在跳出的APP，过10秒才能进行跳出，等待当前数据是否超时，很有可能这个窗口已经关闭了</span></span><br><span class="line"><span class="attr">把所有的数据都给收集进来</span></span><br><span class="line"></span><br><span class="line"><span class="attr">窗口不是为了准确，而是为了数据量，各个窗口中的数据进行累加，类似于滚动的一个效果，可以使用处理时间来进行</span></span><br><span class="line"></span><br><span class="line"><span class="attr">和以前做的开窗是不一样，计算开窗的类的数据结果，如果是放错的话，都是没有关系的</span></span><br></pre></td></tr></tbody></table></figure>

<h2 id="Flink-amp-Clickhouse"><a href="#Flink-amp-Clickhouse" class="headerlink" title="Flink &amp; Clickhouse"></a>Flink &amp; Clickhouse</h2><p>database rank：<a target="_blank" rel="noopener" href="https://db-engines.com/en/ranking">https://db-engines.com/en/ranking</a></p>
<p>flink jdbc example: <a target="_blank" rel="noopener" href="https://ci.apache.org/projects/flink/flink-docs-release-1.13/docs/connectors/datastream/jdbc/">JDBC | Apache Flink</a></p>
<h3 id="1、Clickhouse-封装工具类"><a href="#1、Clickhouse-封装工具类" class="headerlink" title="1、Clickhouse 封装工具类"></a>1、Clickhouse 封装工具类</h3><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&lt;dependency&gt;</span></span><br><span class="line">    <span class="attr">&lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span></span><br><span class="line">    <span class="attr">&lt;artifactId&gt;flink-connector-jdbc_2.11&lt;/artifactId&gt;</span></span><br><span class="line">    <span class="attr">&lt;version&gt;1.13.0&lt;/version&gt;</span></span><br><span class="line"><span class="attr">&lt;/dependency&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">&lt;dependency&gt;</span></span><br><span class="line">    <span class="attr">&lt;groupId&gt;ru.yandex.clickhouse&lt;/groupId&gt;</span></span><br><span class="line">    <span class="attr">&lt;artifactId&gt;clickhouse-jdbc&lt;/artifactId&gt;</span></span><br><span class="line">    <span class="attr">&lt;version&gt;0.3.1&lt;/version&gt;</span></span><br><span class="line">    <span class="attr">&lt;exclusions&gt;</span></span><br><span class="line">        <span class="attr">&lt;exclusion&gt;</span></span><br><span class="line">            <span class="attr">&lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;</span></span><br><span class="line">            <span class="attr">&lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;</span></span><br><span class="line">        <span class="attr">&lt;/exclusion&gt;</span></span><br><span class="line">        <span class="attr">&lt;exclusion&gt;</span></span><br><span class="line">            <span class="attr">&lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;</span></span><br><span class="line">            <span class="attr">&lt;artifactId&gt;jackson-core&lt;/artifactId&gt;</span></span><br><span class="line">        <span class="attr">&lt;/exclusion&gt;</span></span><br><span class="line">    <span class="attr">&lt;/exclusions&gt;</span></span><br><span class="line"><span class="attr">&lt;/dependency&gt;</span></span><br></pre></td></tr></tbody></table></figure>

<p>2、创建clickhouse表</p>
<figure class="highlight sql"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> vistor_stats(</span><br><span class="line">	stt DateTime,</span><br><span class="line">    edt DateTime,</span><br><span class="line">    vc String,</span><br><span class="line">    ch String,</span><br><span class="line">    ar String,</span><br><span class="line">    is_new String,</span><br><span class="line">    uv_ct Uint64,</span><br><span class="line">    pv_ct Uint64,</span><br><span class="line">    sv_ct Uint64,</span><br><span class="line">    uj_ct Uint64,</span><br><span class="line">    dur_sum Uint64,</span><br><span class="line">    ts Uint64</span><br><span class="line">) engine <span class="operator">=</span> ReplacingMergeTree(ts)</span><br><span class="line"><span class="keyword">partition</span> <span class="keyword">by</span> toYYYYMMDD(stt)</span><br><span class="line"><span class="keyword">order</span> <span class="keyword">by</span> (stt,edt,is_new,vc,ch,ar);</span><br></pre></td></tr></tbody></table></figure>

<p>一定要加一个创建时间做一个分区操作</p>
<figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">如何控制对象的属性是否写出去和表的列名做对比</span></span><br><span class="line"><span class="attr">如何去操作勒？</span></span><br><span class="line"><span class="attr">我们可以使用注解的标记来进行开发</span></span><br><span class="line"><span class="meta">@Transient</span> <span class="string">// 短暂的,这个不做序列化操作</span></span><br></pre></td></tr></tbody></table></figure>

<figure class="highlight java"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.wmy.flink.warehourse.utils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.wmy.flink.warehourse.bean.TransientSink;</span><br><span class="line"><span class="keyword">import</span> com.wmy.flink.warehourse.common.WmyConfig;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.connector.jdbc.JdbcConnectionOptions;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.connector.jdbc.JdbcExecutionOptions;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.connector.jdbc.JdbcSink;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.connector.jdbc.JdbcStatementBuilder;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.sink.SinkFunction;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.lang.reflect.Field;</span><br><span class="line"><span class="keyword">import</span> java.sql.PreparedStatement;</span><br><span class="line"><span class="keyword">import</span> java.sql.SQLException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * ClassName:ClickHouseUtil</span></span><br><span class="line"><span class="comment"> * Package:com.wmy.flink.warehourse.utils</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@date</span>:2021/7/25 8:00</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@author</span>:数仓开发工程师</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@email</span>:wmy_2000@163.com</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@Description</span>: clickhouse 工具类</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ClickHouseUtil</span> </span>{</span><br><span class="line">    <span class="comment">// 流中的数据类型是：visitorStats</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; <span class="function">SinkFunction <span class="title">getSink</span><span class="params">(String sql)</span> </span>{</span><br><span class="line">        <span class="keyword">return</span> JdbcSink.sink(</span><br><span class="line">                sql,</span><br><span class="line">                <span class="keyword">new</span> JdbcStatementBuilder&lt;T&gt;() {</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">accept</span><span class="params">(PreparedStatement preparedStatement, T t)</span> <span class="keyword">throws</span> SQLException </span>{</span><br><span class="line">                        <span class="comment">// 封装的泛型也不知道是什么类型的</span></span><br><span class="line">                        <span class="comment">// 反射的方式来获取属性名</span></span><br><span class="line">                        <span class="comment">// javaBean，未来也想调用这个，有些javaBean的属性是不想调出去，在表里面没有，工具类中有，占位符不要</span></span><br><span class="line">                        <span class="comment">// 属性和表的列不对等，属性&gt;=表的列</span></span><br><span class="line">                        <span class="comment">// 有的属性是不想写道clickhouse中</span></span><br><span class="line">                        <span class="comment">// 如何使用注解</span></span><br><span class="line">                        <span class="comment">// 定义一个计数，跳过的属性</span></span><br><span class="line">                        <span class="keyword">int</span> offset = <span class="number">0</span>;</span><br><span class="line">                        Field[] fields = t.getClass().getDeclaredFields();<span class="comment">// 权限问题，拿到所有的属性</span></span><br><span class="line">                        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; fields.length; i++) {</span><br><span class="line">                            Field field = fields[i]; <span class="comment">// 获取具体的字段名，是需要把值放到字段里面</span></span><br><span class="line">                            <span class="comment">// 在字段中获取注解</span></span><br><span class="line">                            TransientSink annotation = field.getAnnotation(TransientSink.class);</span><br><span class="line">                            <span class="keyword">if</span> (annotation != <span class="keyword">null</span>) {</span><br><span class="line">                                offset++;</span><br><span class="line">                                <span class="keyword">continue</span>; <span class="comment">// 这个就跳过操作，不需要进行赋值</span></span><br><span class="line">                            }</span><br><span class="line">                            <span class="comment">// 如何获取值，反射的方式</span></span><br><span class="line">                            field.setAccessible(<span class="keyword">true</span>); <span class="comment">// 可以访问私有属性的值的数据</span></span><br><span class="line">                            <span class="keyword">try</span> {</span><br><span class="line">                                Object value = field.get(t); <span class="comment">// 属性调对象，对象调属性</span></span><br><span class="line">                                <span class="comment">// 给占位符赋值</span></span><br><span class="line">                                preparedStatement.setObject(i + <span class="number">1</span> - offset, value);</span><br><span class="line">                            } <span class="keyword">catch</span> (IllegalAccessException e) {</span><br><span class="line">                                e.printStackTrace();</span><br><span class="line">                            }</span><br><span class="line">                        }</span><br><span class="line">                    }</span><br><span class="line">                },</span><br><span class="line">                JdbcExecutionOptions.builder()</span><br><span class="line">                        .withBatchSize(<span class="number">5</span>)</span><br><span class="line">                        .build(),</span><br><span class="line">                <span class="keyword">new</span> JdbcConnectionOptions.JdbcConnectionOptionsBuilder()</span><br><span class="line">                        .withDriverName(WmyConfig.CLICKHOUSE_DRIVER)</span><br><span class="line">                        .withUrl(WmyConfig.CLICKHOUSE_URL)</span><br><span class="line">                        .build()</span><br><span class="line">        );</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure>

<h2 id="DWS-层-商品主题宽表计算"><a href="#DWS-层-商品主题宽表计算" class="headerlink" title="DWS 层-商品主题宽表计算"></a>DWS 层-商品主题宽表计算</h2><p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210725084247533.png" alt="统计指标"></p>
<h3 id="1-1-需求分析与思路"><a href="#1-1-需求分析与思路" class="headerlink" title="1.1 需求分析与思路"></a>1.1 需求分析与思路</h3><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">从kafka主题中获取数据</span></span><br><span class="line"><span class="attr">明细中有不同种类的skuID，一个订单中的两个skuID相同</span></span><br><span class="line"><span class="attr">电商业务是最熟悉的项目，电商是最熟悉的</span></span><br><span class="line"><span class="attr">支付是和订单来的，支付如何做，订单就如何去做</span></span><br><span class="line"><span class="attr">评价是按照商品就行评价的</span></span><br><span class="line"></span><br><span class="line"><span class="attr">1、从kafka主题中获取数据流</span></span><br><span class="line"><span class="attr">2、把JSON字符串数据流转换为统一数据对象的数据</span></span><br><span class="line"><span class="attr">3、把统一的数据结构流合并成一个流</span></span><br><span class="line"><span class="attr">4、设定事件与水位线</span></span><br><span class="line"><span class="attr">5、分组、开窗、聚合</span></span><br><span class="line"><span class="attr">6、写入Clickhouse</span></span><br><span class="line"></span><br><span class="line"><span class="attr">18个字段</span></span><br><span class="line"><span class="attr">构造者设计模式，javaBean，builder内部类，使用lombok加一个注解就欧克了</span></span><br><span class="line"></span><br><span class="line"><span class="attr">@Data</span></span><br><span class="line"><span class="attr">@Builder</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@Builder注解</span> <span class="string">可以使用构造者方式创建对象，给属性赋值</span></span><br><span class="line"><span class="meta">@Builder.Default</span> <span class="string">在使用构造者方式给属性赋值的时候，属性的初始值会丢失</span></span><br></pre></td></tr></tbody></table></figure>

<h3 id="1-2-功能实现"><a href="#1-2-功能实现" class="headerlink" title="1.2 功能实现"></a>1.2 功能实现</h3><h4 id="1-2-1-封装商品统计实体类ProductStats"><a href="#1-2-1-封装商品统计实体类ProductStats" class="headerlink" title="1.2.1 封装商品统计实体类ProductStats"></a>1.2.1 封装商品统计实体类ProductStats</h4><p>结合注解和反射的方式提高开发的高效</p>
<h4 id="1-2-2-创建ProductStatsApp，从kafka主题获取数据"><a href="#1-2-2-创建ProductStatsApp，从kafka主题获取数据" class="headerlink" title="1.2.2 创建ProductStatsApp，从kafka主题获取数据"></a>1.2.2 创建ProductStatsApp，从kafka主题获取数据</h4><h4 id="1-2-3-把JSON字符串数据流转换为统一数据"><a href="#1-2-3-把JSON字符串数据流转换为统一数据" class="headerlink" title="1.2.3 把JSON字符串数据流转换为统一数据"></a>1.2.3 把JSON字符串数据流转换为统一数据</h4><h4 id="1-2-4-创建电商业务常量类WmyConstant"><a href="#1-2-4-创建电商业务常量类WmyConstant" class="headerlink" title="1.2.4 创建电商业务常量类WmyConstant"></a>1.2.4 创建电商业务常量类WmyConstant</h4><h4 id="1-2-5-把统一的数据结构流合并为一个流"><a href="#1-2-5-把统一的数据结构流合并为一个流" class="headerlink" title="1.2.5 把统一的数据结构流合并为一个流"></a>1.2.5 把统一的数据结构流合并为一个流</h4><h4 id="1-2-6-设定事件事件与水位线"><a href="#1-2-6-设定事件事件与水位线" class="headerlink" title="1.2.6 设定事件事件与水位线"></a>1.2.6 设定事件事件与水位线</h4><h4 id="1-2-7-分组、开窗、聚合"><a href="#1-2-7-分组、开窗、聚合" class="headerlink" title="1.2.7 分组、开窗、聚合"></a>1.2.7 分组、开窗、聚合</h4><h4 id="1-2-8-补充商品维度信息"><a href="#1-2-8-补充商品维度信息" class="headerlink" title="1.2.8 补充商品维度信息"></a>1.2.8 补充商品维度信息</h4><h4 id="1-2-9-写入Clickhouse"><a href="#1-2-9-写入Clickhouse" class="headerlink" title="1.2.9 写入Clickhouse"></a>1.2.9 写入Clickhouse</h4><h4 id="1-2-10-整体测试"><a href="#1-2-10-整体测试" class="headerlink" title="1.2.10 整体测试"></a>1.2.10 整体测试</h4><p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210725100601039.png" alt="结果展示"></p>
<h2 id="DWS层-关键词主题表（Flink-SQL）"><a href="#DWS层-关键词主题表（Flink-SQL）" class="headerlink" title="DWS层-关键词主题表（Flink SQL）"></a>DWS层-关键词主题表（Flink SQL）</h2><p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210725101011140.png" alt="需求描述"></p>
<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210725101058854.png" alt="关键词展示"></p>
<h3 id="4-1-需求分析与思路"><a href="#4-1-需求分析与思路" class="headerlink" title="4.1 需求分析与思路"></a>4.1 需求分析与思路</h3><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">1、定义Table环境</span></span><br><span class="line"><span class="attr">2、把数据流定义为动态表</span></span><br><span class="line"><span class="attr">3、通过SQL查询出结果表</span></span><br><span class="line"><span class="attr">4、把结果表转换为数据流</span></span><br><span class="line"><span class="attr">5、把数据流写入目标数据库</span></span><br><span class="line"></span><br><span class="line"><span class="meta">如果是Flink官方支持的数据库，也可以直接把目标表定义为动态表，用insert</span> <span class="string">into写入，由于Clickhouse目前官方没有支持的JDBC连接器（目前支持MySQL等），也可以制作自定义的Sink，实现官方不支持的连接器，但是比较繁琐</span></span><br></pre></td></tr></tbody></table></figure>

<h3 id="4-2-环境准备"><a href="#4-2-环境准备" class="headerlink" title="4.2  环境准备"></a>4.2  环境准备</h3><h4 id="4-2-1-在pom-xml文件中添加Flink-SQL相关依赖"><a href="#4-2-1-在pom-xml文件中添加Flink-SQL相关依赖" class="headerlink" title="4.2.1 在pom.xml文件中添加Flink SQL相关依赖"></a>4.2.1 在pom.xml文件中添加Flink SQL相关依赖</h4><figure class="highlight properties"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&lt;dependency&gt;</span></span><br><span class="line">    <span class="attr">&lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span></span><br><span class="line">    <span class="attr">&lt;artifactId&gt;flink-table-api-java-bridge_${scala.version}&lt;/artifactId&gt;</span></span><br><span class="line">    <span class="attr">&lt;version&gt;${flink.version}&lt;/version&gt;</span></span><br><span class="line"><span class="attr">&lt;/dependency&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">&lt;dependency&gt;</span></span><br><span class="line">    <span class="attr">&lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span></span><br><span class="line">    <span class="attr">&lt;artifactId&gt;flink-table-planner-blink_${scala.version}&lt;/artifactId&gt;</span></span><br><span class="line">    <span class="attr">&lt;version&gt;${flink.version}&lt;/version&gt;</span></span><br><span class="line"><span class="attr">&lt;/dependency&gt;</span></span><br></pre></td></tr></tbody></table></figure>

<h3 id="4-3-测试"><a href="#4-3-测试" class="headerlink" title="4.3 测试"></a>4.3 测试</h3><p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210725103301614.png" alt="建表"></p>
<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210725102655927.png" alt="结果展示"></p>
<p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210725103404645.png" alt="关键词搜索"></p>
<h3 id="4-4-关键主题、扩展需求"><a href="#4-4-关键主题、扩展需求" class="headerlink" title="4.4 关键主题、扩展需求"></a>4.4 关键主题、扩展需求</h3><p><img src="/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/image-20210725103454212.png" alt="总结"></p>
<h2 id="ADS-应用层"><a href="#ADS-应用层" class="headerlink" title="ADS 应用层"></a>ADS 应用层</h2>
                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">情深骚明</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://example.com/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/">http://example.com/2021/07/13/flink%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint polocy. If reproduced, please indicate source
                    <a href="/about" target="_blank">情深骚明</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/flink/">
                                    <span class="chip bg-color">flink</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/2021/07/14/maxwell/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/10.jpg" class="responsive-img" alt="maxwell">
                        
                        <span class="card-title">maxwell</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-07-14
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%95%B0%E4%BB%93/" class="post-category">
                                    数仓
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%95%B0%E4%BB%93/">
                        <span class="chip bg-color">数仓</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2021/07/12/Flink1-12%E5%86%85%E6%A0%B8%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/1.jpg" class="responsive-img" alt="Flink1.12内核源码解析">
                        
                        <span class="card-title">Flink1.12内核源码解析</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-07-12
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/flink/" class="post-category">
                                    flink
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/flink/">
                        <span class="chip bg-color">flink</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        font-size: 15px;
        color: #42b983;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="436514312"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='false'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2019-2021</span>
            
            <span id="year">2019</span>
            <a href="/about" target="_blank">情深骚明</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/wmyBigdata-1" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:2647716549@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2647716549" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2647716549" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







</div>
    </div>

    <div class="progress-bar"></div>
          
        <span id="busuanzi_container_site_pv" style='display:none'></span>
            <i class="fa fa-heart-o"></i>
            本站总访问量 <span id="busuanzi_value_site_pv" class="white-color"></span>

    

    
        <span id="busuanzi_container_site_uv" style='display:none'></span>
            人次,&nbsp;访客数 <span id="busuanzi_value_site_uv" class="white-color"></span> 人.

    

    
        <span id="busuanzi_container_site_pv" style='display:none'></span>
        <i class="fa fa-eye fa-fw"></i>Read Count:&nbsp;&nbsp;
        <span id="busuanzi_value_page_pv" ></span>

    

    <span id="busuanzi_container_site_pv" style='display:none'></span>
    <span id="busuanzi_container_site_uv" style='display:none'></span>
</footer>



    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

	
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"react":{"opacity":0.7}});</script></body>

</html>
